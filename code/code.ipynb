{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/victoriastasik/Documents/Very_large_distributed_data_volumes_exercise3/code'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: haversine==2.8.0 in /usr/local/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (2.8.0)\n",
      "Requirement already satisfied: pymongo==4.5.0 in /usr/local/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (4.5.0)\n",
      "Requirement already satisfied: tabulate==0.9.0 in /usr/local/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (0.9.0)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.11/site-packages (from pymongo==4.5.0->-r requirements.txt (line 2)) (2.4.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint \n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DbConnector.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DbConnector:\n",
    "    \"\"\"\n",
    "    Connects to the MongoDB server on the Ubuntu virtual machine.\n",
    "    Connector needs HOST, USER and PASSWORD to connect.\n",
    "\n",
    "    Example:\n",
    "    HOST = \"tdt4225-00.idi.ntnu.no\" // Your server IP address/domain name\n",
    "    USER = \"testuser\" // This is the user you created and added privileges for\n",
    "    PASSWORD = \"test123\" // The password you set for said user\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 DATABASE='my_db',\n",
    "                 HOST=\"tdt4225-19.idi.ntnu.no\",\n",
    "                 USER=\"team19\",\n",
    "                 PASSWORD=\"team19*\"):\n",
    "        uri = \"mongodb://%s:%s@%s/%s\" % (USER, PASSWORD, HOST, DATABASE)\n",
    "        # Connect to the databases\n",
    "        try:\n",
    "            self.client = MongoClient('mongodb://team19:team19*@tdt4225-19.idi.ntnu.no:27017/my_db')\n",
    "            self.db = self.client[DATABASE]\n",
    "        except Exception as e:\n",
    "            print(\"ERROR: Failed to connect to db:\", e)\n",
    "\n",
    "        # get database information\n",
    "        print(\"You are connected to the database:\", self.db.name)\n",
    "        print(\"-----------------------------------------------\\n\")\n",
    "\n",
    "    def close_connection(self):\n",
    "        # close the cursor\n",
    "        # close the DB connection\n",
    "        self.client.close()\n",
    "        print(\"\\n-----------------------------------------------\")\n",
    "        print(\"Connection to %s-db is closed\" % self.db.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are connected to the database: my_db\n",
      "-----------------------------------------------\n",
      "\n",
      "Created collection:  Collection(Database(MongoClient(host=['tdt4225-19.idi.ntnu.no:27017'], document_class=dict, tz_aware=False, connect=True), 'my_db'), 'Person')\n",
      "[]\n",
      "{'_id': 1,\n",
      " 'courses': [{'code': 'TDT4225',\n",
      "              'name': ' Very Large, Distributed Data Volumes'},\n",
      "             {'code': 'BOI1001', 'name': ' How to become a boi or boierinnaa'}],\n",
      " 'name': 'Bobby'}\n",
      "{'_id': 2,\n",
      " 'courses': [{'code': 'TDT02', 'name': ' Advanced, Distributed Systems'}],\n",
      " 'name': 'Bobby'}\n",
      "{'_id': 3, 'name': 'Bobby'}\n",
      "[]\n",
      "\n",
      "-----------------------------------------------\n",
      "Connection to my_db-db is closed\n"
     ]
    }
   ],
   "source": [
    "class ExampleProgram:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.connection = DbConnector()\n",
    "        self.client = self.connection.client\n",
    "        self.db = self.connection.db\n",
    "\n",
    "    def create_coll(self, collection_name):\n",
    "        collection = self.db.create_collection(collection_name)    \n",
    "        print('Created collection: ', collection)\n",
    "\n",
    "    def insert_documents(self, collection_name):\n",
    "        docs = [\n",
    "            {\n",
    "                \"_id\": 1,\n",
    "                \"name\": \"Bobby\",\n",
    "                \"courses\": \n",
    "                    [\n",
    "                    {'code':'TDT4225', 'name': ' Very Large, Distributed Data Volumes'},\n",
    "                    {'code':'BOI1001', 'name': ' How to become a boi or boierinnaa'}\n",
    "                    ] \n",
    "            },\n",
    "            {\n",
    "                \"_id\": 2,\n",
    "                \"name\": \"Bobby\",\n",
    "                \"courses\": \n",
    "                    [\n",
    "                    {'code':'TDT02', 'name': ' Advanced, Distributed Systems'},\n",
    "                    ] \n",
    "            },\n",
    "            {\n",
    "                \"_id\": 3,\n",
    "                \"name\": \"Bobby\",\n",
    "            }\n",
    "        ]  \n",
    "        collection = self.db[collection_name]\n",
    "        collection.insert_many(docs)\n",
    "        \n",
    "    def fetch_documents(self, collection_name):\n",
    "        collection = self.db[collection_name]\n",
    "        documents = collection.find({})\n",
    "        for doc in documents: \n",
    "            pprint(doc)\n",
    "        \n",
    "\n",
    "    def drop_coll(self, collection_name):\n",
    "        collection = self.db[collection_name]\n",
    "        collection.drop()\n",
    "\n",
    "        \n",
    "    def show_coll(self):\n",
    "        collections = self.client['test'].list_collection_names()\n",
    "        print(collections)\n",
    "         \n",
    "\n",
    "\n",
    "def main():\n",
    "    program = None\n",
    "    try:\n",
    "        program = ExampleProgram()\n",
    "        program.create_coll(collection_name=\"Person\")\n",
    "        program.show_coll()\n",
    "        program.insert_documents(collection_name=\"Person\")\n",
    "        program.fetch_documents(collection_name=\"Person\")\n",
    "        program.drop_coll(collection_name=\"Person\")\n",
    "        # program.drop_coll(collection_name='person')\n",
    "        # program.drop_coll(collection_name='users')\n",
    "        # Check that the table is dropped\n",
    "        program.show_coll()\n",
    "    except Exception as e:\n",
    "        print(\"ERROR: Failed to use database:\", e)\n",
    "    finally:\n",
    "        if program:\n",
    "            program.connection.close_connection()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/victoriastasik/Documents/Very_large_distributed_data_volumes_exercise3/dataset/dataset/Data\n"
     ]
    }
   ],
   "source": [
    "# we go to the Data folder\n",
    "os.chdir(\"..\")\n",
    "path = os.getcwd()\n",
    "os.chdir(\"/Users/victoriastasik/Documents/Very_large_distributed_data_volumes_exercise3/dataset/dataset/Data\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_user_dataframe():\n",
    "    # we get the list of all the diferent directory names (users ids) and we sort the list\n",
    "    usersID =  os.listdir()\n",
    "    usersID.sort()\n",
    "\n",
    "    # we go back to the dataset directory and we read the labeled_ids.txt file\n",
    "    os.chdir(\"..\")\n",
    "    with open('labeled_ids.txt') as f:\n",
    "        labeled_ids = f.readlines()\n",
    "    f.close()\n",
    "    os.chdir(\"/Users/victoriastasik/Documents/Very_large_distributed_data_volumes_exercise3/dataset/dataset/Data\")\n",
    "        \n",
    "    # we delete the \\n in each string\n",
    "    for i in range (0, len(labeled_ids)):\n",
    "        labeled_ids[i] = labeled_ids[i].strip()\n",
    "\n",
    "    # we check if each user has a label or not and we save the info in a list\n",
    "    # the indexes of has_labels and id lists are correponding\n",
    "    has_labels = []\n",
    "    for i in usersID : \n",
    "        if i in labeled_ids : \n",
    "            has_labels.append(True)\n",
    "        else:\n",
    "            has_labels.append(False)\n",
    "\n",
    "    user_table = {'user_id': usersID, 'has_labels': has_labels}\n",
    "    user_dataframe = pd.DataFrame(user_table)\n",
    "    return user_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info_from_labels_txt_file() :\n",
    "    user_id_list = []\n",
    "    transportation_mode_list = []\n",
    "    start_date_time_list = []\n",
    "    end_date_time_list = []\n",
    "\n",
    "    for dirpath, dirnames, filenames in os.walk(os.getcwd()):\n",
    "        for filename in filenames:\n",
    "            # if there is a labels.txt file, we save the info\n",
    "            if filename.endswith('.txt'):\n",
    "                try :\n",
    "                    with open(os.path.join(dirpath, filename)) as f:\n",
    "                        lines = f.readlines()\n",
    "\n",
    "                        # skip the header\n",
    "                        lines = lines[1:]\n",
    "\n",
    "                        for line in lines:\n",
    "                            \n",
    "                            # we get the info of one line\n",
    "                            data = line.split()\n",
    "\n",
    "                            # we save each information into the correct list\n",
    "                            last_directory_name = os.path.basename(dirpath)\n",
    "                            user_id_list.append(last_directory_name)\n",
    "\n",
    "                            transportation_mode_list.append(data[4])\n",
    "\n",
    "                            start_date = data[0]\n",
    "                            start_time = data[1]\n",
    "                            end_date = data[2]\n",
    "                            end_time = data[3]\n",
    "                            start_datetime_str = start_date + \" \" + start_time\n",
    "                            end_datetime_str = end_date + \" \" + end_time\n",
    "                            start_datetime_str = start_datetime_str.replace('/', '-')\n",
    "                            end_datetime_str = end_datetime_str.replace('/', '-')\n",
    "                            combined_start_datetime = datetime.strptime(start_datetime_str, \"%Y-%m-%d %H:%M:%S\")\n",
    "                            combined_end_datetime = datetime.strptime(end_datetime_str, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "                            start_date_time_list.append(combined_start_datetime)\n",
    "                            end_date_time_list.append(combined_end_datetime)\n",
    "                    f.close()\n",
    "\n",
    "                # error handling\n",
    "                except FileNotFoundError:\n",
    "                    print(f\"the file {filename} doesn't exist.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error: {e}\")\n",
    "\n",
    "    return user_id_list, transportation_mode_list, start_date_time_list, end_date_time_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info_from_plt_file() :\n",
    "    activity = 0\n",
    "    activity_id_list = []\n",
    "    user_id_list = []\n",
    "    lat_list = []\n",
    "    long_list = []\n",
    "    altitude_list = []\n",
    "    date_days_list = []\n",
    "    current_date_time_list = []\n",
    "    start_date_time_list = []\n",
    "    end_date_time_list = []\n",
    "\n",
    "    for dirpath, dirnames, filenames in os.walk(os.getcwd()):\n",
    "        for filename in filenames:\n",
    "\n",
    "            # we get the information of each plt file\n",
    "            if filename.endswith('.plt'):\n",
    "                try :\n",
    "                    with open(os.path.join(dirpath, filename)) as f:\n",
    "                        lines = f.readlines()\n",
    "\n",
    "                        # skip the first 6 lines\n",
    "                        lines = lines[6:]\n",
    "\n",
    "                        # check the length of the plt file\n",
    "                        if len(lines) <= 2500:\n",
    "\n",
    "                            # we get the start and end date of each plt file\n",
    "                            start_line= lines[0].split(',')\n",
    "                            start_date = start_line[5]\n",
    "                            start_time = start_line[6]\n",
    "                            start_datetime = start_date + ' ' + start_time\n",
    "                            start_datetime = start_datetime.rstrip('\\n')\n",
    "                            start_datetime = datetime.strptime(start_datetime, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "                            end_line = lines[len(lines)-1].split(',')\n",
    "                            end_date = end_line[5]\n",
    "                            end_time = end_line[6]\n",
    "                            end_datetime = end_date + ' ' + end_time\n",
    "                            end_datetime = end_datetime.rstrip('\\n')\n",
    "                            end_datetime = datetime.strptime(end_datetime, \"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "                            # we save the information of each line of the plt file\n",
    "                            for line in lines:\n",
    "\n",
    "                                data = line.split(',')\n",
    "\n",
    "                                activity_id_list.append(activity)\n",
    "\n",
    "                                parent_directory = os.path.dirname(dirpath)\n",
    "                                directory_name = os.path.basename(parent_directory) \n",
    "                                user_id_list.append(directory_name)\n",
    "\n",
    "                                lat_list.append(float(data[0]))\n",
    "                                long_list.append(float(data[1]))\n",
    "                                altitude_list.append(int(float(data[3])))\n",
    "                                date_days_list.append(float(data[4]))\n",
    "\n",
    "                                date = data[5]\n",
    "                                time = data[6]\n",
    "                                datetime_draft = date + ' ' + time\n",
    "                                datetime_draft = datetime_draft.rstrip('\\n')\n",
    "                                combined_datetime = datetime.strptime(datetime_draft, \"%Y-%m-%d %H:%M:%S\")\n",
    "                                current_date_time_list.append(combined_datetime)\n",
    "\n",
    "                                start_date_time_list.append(start_datetime)\n",
    "                                end_date_time_list.append(end_datetime)\n",
    "\n",
    "                    f.close()\n",
    "                    activity +=1\n",
    "                  \n",
    "                except FileNotFoundError:\n",
    "                    print(f\"the file {filename} doesn't exist.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error: {e}\")\n",
    "                    \n",
    "    return activity_id_list, user_id_list, lat_list, long_list, altitude_list, date_days_list, current_date_time_list, start_date_time_list, end_date_time_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_activity_and_trackpoint_dataframe():    \n",
    "    # getting info from txt files\n",
    "    user_id_list, transportation_mode_list, start_date_time_list, end_date_time_list = get_info_from_labels_txt_file()\n",
    "    labels_txt = {'user_id': user_id_list, 'transportation_mode': transportation_mode_list, 'start_datetime': start_date_time_list, 'end_datetime': end_date_time_list}\n",
    "    labels_txt_df = pd.DataFrame(labels_txt)\n",
    "\n",
    "    # getting info from plt files\n",
    "    activity_id_list, user_id_list_2, lat_list, long_list, altitude_list, date_days_list, current_date_time_list, start_date_time_list2, end_date_time_list2 = get_info_from_plt_file()\n",
    "    plt = {'activity_id': activity_id_list, 'user_id': user_id_list_2, 'lat': lat_list, 'long': long_list, 'altitude': altitude_list, 'date_days': date_days_list, \n",
    "           'current_date_time': current_date_time_list, 'start_datetime': start_date_time_list2, 'end_datetime': end_date_time_list2}\n",
    "    plt_df = pd.DataFrame(plt)\n",
    "\n",
    "    # merging both dataframes\n",
    "    merged_df = pd.merge(plt_df, labels_txt_df, on=['user_id', 'start_datetime', 'end_datetime'], how='left')\n",
    "\n",
    "    # creating activity table\n",
    "    activity_table = merged_df[['activity_id','user_id', 'transportation_mode', 'start_datetime', 'end_datetime']]\n",
    "    activity_table = activity_table.fillna(\"missing\")\n",
    "    activity_table['start_datetime'] = activity_table['start_datetime'].astype(str) # converting into string to be able to insert into the sql table\n",
    "    activity_table['end_datetime'] = activity_table['end_datetime'].astype(str)\n",
    "    activity_table = activity_table.drop_duplicates()\n",
    "\n",
    "    # creating trackpoint table\n",
    "    trackpoint_table = merged_df[['activity_id','lat', 'long', 'altitude', 'date_days', 'current_date_time']]\n",
    "    trackpoint_table.rename(columns={'current_date_time': 'date_time'}, inplace=True)\n",
    "    trackpoint_table['id'] = range(1, len(trackpoint_table) + 1)\n",
    "    trackpoint_table = trackpoint_table[['id'] + [col for col in trackpoint_table.columns if col != 'id']]\n",
    "    trackpoint_table['date_time'] = trackpoint_table['date_time'].astype(str)\n",
    "\n",
    "    return activity_table, trackpoint_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Task1:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.connection = DbConnector()\n",
    "        self.client = self.connection.client\n",
    "        self.db = self.connection.db\n",
    "\n",
    "    def create_coll(self, collection_name):\n",
    "        collection = self.db.create_collection(collection_name)    \n",
    "        print('Created collection: ', collection)\n",
    "\n",
    "    def insert_activity_data(self, user_table, activity_table):\n",
    "        merged_df = pd.merge(user_table, activity_table, on=['user_id'])\n",
    "\n",
    "        result_list = []\n",
    "        for index, row in merged_df.iterrows():\n",
    "            user_info = {'user_id': row['user_id'], 'has_labels': row['has_labels']}\n",
    "            entry = {\n",
    "                '_id': index,\n",
    "                'activity_id': row['activity_id'],\n",
    "                'user_info': user_info,\n",
    "                'transportation_mode': row['transportation_mode'],\n",
    "                'start_datetime': row['start_datetime'],\n",
    "                'end_datetime': row['end_datetime']\n",
    "            }\n",
    "            result_list.append(entry)\n",
    "        \n",
    "        collection = self.db[\"Activity\"]\n",
    "        collection.insert_many(result_list)\n",
    "\n",
    "    def insert_trackpoint_data(self, trackpoint_table):\n",
    "        \n",
    "        result_list = []\n",
    "        for index, row in trackpoint_table.iterrows():\n",
    "            entry = {\n",
    "                '_id': row['id'],\n",
    "                'activity_id': row['activity_id'],\n",
    "                'lat': row['lat'],\n",
    "                'lon': row['long'],\n",
    "                'altitude': row['altitude'],\n",
    "                'date_days': row['date_days'],\n",
    "                'date_time': row['date_time']\n",
    "            }\n",
    "            result_list.append(entry)\n",
    "        \n",
    "        collection = self.db[\"TrackPoint\"]\n",
    "        collection.insert_many(result_list)\n",
    "\n",
    "    def compute_aggregated_query(self, collection_name, pipeline):\n",
    "        collection = self.db[collection_name]\n",
    "        result = collection.aggregate(pipeline)\n",
    "        for i in result: \n",
    "            pprint(i)\n",
    "        \n",
    "    def fetch_documents(self, collection_name):\n",
    "        collection = self.db[collection_name]\n",
    "        documents = collection.find({})\n",
    "        for doc in documents: \n",
    "            pprint(doc)\n",
    "        \n",
    "    def drop_coll(self, collection_name):\n",
    "        collection = self.db[collection_name]\n",
    "        collection.drop()\n",
    "\n",
    "        \n",
    "    def show_coll(self):\n",
    "        collections = self.client['my_db'].list_collection_names()\n",
    "        print(collections)         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are connected to the database: my_db\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Connection to my_db-db is closed\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    program = None\n",
    "    try:\n",
    "        activity_table, trackpoint_table = creating_activity_and_trackpoint_dataframe()\n",
    "        user_table = creating_user_dataframe()\n",
    "        \n",
    "        program = Task1()\n",
    "\n",
    "        program.drop_coll(collection_name=\"Activity\")\n",
    "        program.drop_coll(collection_name=\"TrackPoint\")\n",
    "\n",
    "        program.create_coll(collection_name=\"Activity\")\n",
    "        program.create_coll(collection_name=\"TrackPoint\")\n",
    "        program.show_coll()\n",
    "        \n",
    "        program.insert_activity_data(user_table, activity_table)\n",
    "        program.insert_trackpoint_data(trackpoint_table)\n",
    "\n",
    "        program.fetch_documents(collection_name=\"Activity\")\n",
    "        program.fetch_documents(collection_name=\"TrackPoint\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"ERROR: Failed to use database:\", e)\n",
    "    finally:\n",
    "        if program:\n",
    "            program.connection.close_connection()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def haversine_distance(coord1, coord2):\n",
    "    # Radius of the Earth in kilometers\n",
    "    radius = 6371\n",
    "\n",
    "    # Extract longitude and latitude from the coordinate tuples\n",
    "    lon1, lat1 = coord1\n",
    "    lon2, lat2 = coord2\n",
    "\n",
    "    # Convert latitude and longitude from degrees to radians\n",
    "    lon1, lat1, lon2, lat2 = map(math.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # Haversine formula\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2\n",
    "    c = 2 * math.asin(math.sqrt(a))\n",
    "\n",
    "    # Calculate the distance\n",
    "    distance = radius * c\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Task2:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.connection = DbConnector()\n",
    "        self.client = self.connection.client\n",
    "        self.db = self.connection.db\n",
    "\n",
    "    ##############################################################################################################\n",
    "\n",
    "    def query1(self):\n",
    "        collection_a = self.db['Activity']\n",
    "        collection_t = self.db['TrackPoint']\n",
    "\n",
    "        pipeline_t = [\n",
    "        {\n",
    "            '$group': {\n",
    "                '_id': None,\n",
    "                'count': {'$sum': 1}\n",
    "            }\n",
    "        }]\n",
    "\n",
    "        pipeline_a = [\n",
    "        {\n",
    "            \"$group\": {\n",
    "                \"_id\": None,\n",
    "                \"user_ids\": {\"$addToSet\": \"$user_info.user_id\"},\n",
    "                \"activity_ids\": {\"$addToSet\": \"$activity_id\"}\n",
    "            }   \n",
    "        },\n",
    "        {\n",
    "            \"$project\": {\n",
    "            \"user_count\": {\"$size\": \"$user_ids\"},\n",
    "            \"activity_count\": {\"$size\": \"$activity_ids\"}\n",
    "            }\n",
    "        }\n",
    "        ]\n",
    "\n",
    "        cursor_t = collection_t.aggregate(pipeline_t)\n",
    "        cursor_a = collection_a.aggregate(pipeline_a)\n",
    "        result_t = list(cursor_t)\n",
    "        result_a = list(cursor_a)\n",
    "        if result_t and result_a:\n",
    "            count_t = result_t[0]['count']\n",
    "            count_u = result_a[0]['user_count']\n",
    "            count_a = result_a[0]['activity_count']\n",
    "            print('Tot TrackPoints: ' + str(count_t) + \n",
    "                  '\\n' + 'Tot Users: ' + str(count_u) +\n",
    "                  '\\n' + 'Tot Activities: ' + str(count_a))\n",
    "        else:\n",
    "            return print('Error')\n",
    "        \n",
    "    ##############################################################################################################\n",
    "\n",
    "    def query2(self):\n",
    "        pipeline2 = [\n",
    "            {\n",
    "                \"$group\": {\n",
    "                \"_id\": \"$user_info.user_id\",\n",
    "                    \"nb\": { \"$sum\": 1} \n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$group\": {\n",
    "                \"_id\": None,\n",
    "                \"avg_nb\": { \"$avg\": \"$nb\" }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "        result2 = list(self.db[\"Activity\"].aggregate(pipeline2))\n",
    "\n",
    "        for doc in result2 :\n",
    "            print(\"Average number of activities per user :\", doc['avg_nb'])\n",
    "\n",
    "    ##############################################################################################################\n",
    "\n",
    "    def query3(self):\n",
    "        pipeline = [\n",
    "            {\n",
    "                \"$group\": {\n",
    "                    \"_id\": \"$user_info.user_id\",\n",
    "                    \"count\": { \"$sum\": 1 }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$sort\": {\"count\": -1}\n",
    "            },\n",
    "            {\n",
    "                \"$limit\": 20\n",
    "            }\n",
    "        ]\n",
    "        result = list(self.db.Activity.aggregate(pipeline))\n",
    "\n",
    "        for doc in result:\n",
    "            pprint(doc)\n",
    "\n",
    "    ##############################################################################################################\n",
    "\n",
    "    def query4(self):\n",
    "        collection_a = self.db['Activity']\n",
    "\n",
    "        pipeline = [\n",
    "            {\n",
    "                '$match': {\n",
    "                    'transportation_mode': 'taxi'\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                '$group': {\n",
    "                    '_id': '$user_info.user_id'\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        cursor_a = collection_a.aggregate(pipeline)\n",
    "        result_a = list(cursor_a)\n",
    "\n",
    "        if result_a:\n",
    "            print('Users that have taken a taki:')\n",
    "            for u in result_a:\n",
    "                pprint(u['_id'])\n",
    "        else:\n",
    "            print(\"Error\")\n",
    "\n",
    "    ##############################################################################################################\n",
    "\n",
    "    def query5(self):\n",
    "        pipeline5 = [\n",
    "            {\n",
    "                \"$match\": {\n",
    "                \"transportation_mode\":{\"$ne\": 'missing'} \n",
    "                \n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$group\": {\n",
    "                \"_id\": \"$transportation_mode\",\n",
    "                    \"nb\": { \"$sum\": 1} \n",
    "                }\n",
    "            }\n",
    "        ]  \n",
    "        result5 = list(self.db[\"Activity\"].aggregate(pipeline5))\n",
    "\n",
    "        for doc in result5 :\n",
    "            print(\"transportation_mode : \",doc[\"_id\"], \", number of activities : \", doc[\"nb\"])\n",
    "\n",
    "    ##############################################################################################################\n",
    "\n",
    "    def query6a(self):\n",
    "        pipeline = [\n",
    "            {\n",
    "                \"$project\": {\n",
    "                    \"year\": { \"$year\": { \"$dateFromString\": { \"dateString\": \"$start_datetime\" } }}\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$group\": {\n",
    "                    \"_id\": \"$year\",\n",
    "                    \"count\": { \"$sum\": 1 }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$sort\": { \"count\": -1 }\n",
    "            },\n",
    "            {\n",
    "                \"$limit\": 1\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        result = list(self.db.Activity.aggregate(pipeline))\n",
    "\n",
    "        for doc in result:\n",
    "            pprint(doc)\n",
    "\n",
    "    ##############################################################################################################\n",
    "\n",
    "    def query6b(self):\n",
    "        pipeline = [\n",
    "            {\n",
    "                \"$addFields\": {\n",
    "                    \"start_datetime\": {\n",
    "                        \"$dateFromString\": {\n",
    "                            \"dateString\": \"$start_datetime\",\n",
    "                            \"format\": \"%Y-%m-%d %H:%M:%S\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"end_datetime\": {\n",
    "                        \"$dateFromString\": {\n",
    "                            \"dateString\": \"$end_datetime\",\n",
    "                            \"format\": \"%Y-%m-%d %H:%M:%S\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$project\": {\n",
    "                    \"year\": { \"$year\": \"$start_datetime\" },\n",
    "                    \"duration\": {\n",
    "                        \"$divide\": [\n",
    "                            { \"$subtract\": [\"$end_datetime\", \"$start_datetime\"] },\n",
    "                            1000 * 60 * 60\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$group\": {\n",
    "                    \"_id\": \"$year\",\n",
    "                    \"total_hours\": { \"$sum\": \"$duration\" }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$sort\": { \"total_hours\": -1 }\n",
    "            },\n",
    "            {\n",
    "                \"$limit\": 1\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        result = list(self.db.Activity.aggregate(pipeline))\n",
    "\n",
    "        for doc in result:\n",
    "            pprint(doc)  \n",
    "\n",
    "    ##############################################################################################################\n",
    "\n",
    "    def query7(self):\n",
    "        collection_a = self.db['Activity']\n",
    "\n",
    "        user_id = '112'\n",
    "        start_date = '2008-01-01 00:00:00'\n",
    "        end_date = '2008-12-31 23:59:59'\n",
    "        mode = 'walk'\n",
    "\n",
    "        pipeline = [\n",
    "            {\n",
    "                '$match': {\n",
    "                    'user_info.user_id': user_id,\n",
    "                    'start_datetime': {\n",
    "                        '$gte': start_date,\n",
    "                        '$lte': end_date\n",
    "                    },\n",
    "                    'transportation_mode': mode\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$lookup\": {\n",
    "                    \"from\": \"TrackPoint\", \n",
    "                    \"localField\": \"_id\",  \n",
    "                    \"foreignField\": \"activity_id\", \n",
    "                    \"as\": \"trackpoint_info\"  \n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                # we wanna unwind the 'trackpoints' array to make it easier to work with\n",
    "                '$unwind': '$trackpoint_info'\n",
    "            },\n",
    "            {\n",
    "                \"$sort\": {\n",
    "                    \"trackpoints.date_time\": 1,\n",
    "                    \"activity_id\": 1  # Sort by date_time and then by activity_id\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        cursor_a = collection_a.aggregate(pipeline)\n",
    "        result_a = list(cursor_a)\n",
    "\n",
    "        count = 0\n",
    "\n",
    "        tot_distance_per_act = 0\n",
    "        list_tot_distances = []\n",
    "        prev_coords = []\n",
    "        prev_activityID = 0\n",
    "\n",
    "        if result_a:\n",
    "\n",
    "            for r in result_a:\n",
    "                lat = r['trackpoint_info']['lat']\n",
    "                lon = r['trackpoint_info']['lon']\n",
    "                activity_id = r['_id']\n",
    "\n",
    "                coords = [lon, lat]\n",
    "                \n",
    "                if count == 0:\n",
    "                    prev_coords = [lon, lat]\n",
    "                    prev_activityID = activity_id\n",
    "                    count += 1\n",
    "                    continue\n",
    "               \n",
    "                d = haversine_distance(prev_coords, coords)\n",
    "                if prev_activityID != activity_id:\n",
    "                    list_tot_distances.append(d) #list of the distances for the different activities\n",
    "                else:\n",
    "                    tot_distance_per_act += d #tot distance per same activity\n",
    "\n",
    "                prev_coords = [lon, lat]\n",
    "                prev_activityID = activity_id\n",
    "            \n",
    "            tot_distance = 0\n",
    "            print(tot_distance_per_act)\n",
    "            #tot_distance = sum(tot_distance_per_act)\n",
    "            # for d in tot_distance_per_act:\n",
    "            #     tot_distance += d\n",
    "\n",
    "            print('Tot Distance for the user 112:')\n",
    "            print(tot_distance)\n",
    "        else:\n",
    "            print(\"Error\")\n",
    "\n",
    "    ##############################################################################################################\n",
    "\n",
    "    def query8(self):\n",
    "        pipeline8 = [\n",
    "                \n",
    "                {\n",
    "                    \"$sort\": { \"trackpoint_id\": 1 }\n",
    "                },\n",
    "                {\n",
    "                    \"$group\": {\n",
    "                    \"_id\": \"$activity_id\",\n",
    "                    \"list_alt\": {\"$push\": \"$altitude\"},\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"$lookup\": {\n",
    "                    \"from\": \"Activity\",\n",
    "                    \"localField\": \"_id\",\n",
    "                    \"foreignField\": \"activity_id\",\n",
    "                    \"as\": \"activity\"\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"$project\": {\n",
    "                        \"user_id\" : \"$activity.user_info.user_id\",\n",
    "                        \"activity_id\": \"$_id\",\n",
    "                        \"list_alt\": \"$list_alt\" \n",
    "                }\n",
    "                }\n",
    "                ]\n",
    "        result8 = list(self.db[\"TrackPoint\"].aggregate(pipeline8))\n",
    "\n",
    "        alt_user = {}\n",
    "        for activite in result8: \n",
    "            prev_alt = 0\n",
    "            alt_act = 0\n",
    "            user= activite[\"user_id\"][0]\n",
    "            for alt in activite[\"list_alt\"] :\n",
    "                if prev_alt != 0 and prev_alt < alt :\n",
    "                    alt_act = alt_act + (alt-prev_alt)\n",
    "                prev_alt = alt\n",
    "            if user in alt_user.keys() :\n",
    "                alt_user[user]= alt_user[user] + alt_act\n",
    "            else : \n",
    "                alt_user[user]= alt_act\n",
    "\n",
    "        dico_sorted = {k: v for k, v in sorted(alt_user.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "        for i, (key, value) in enumerate(dico_sorted.items()):\n",
    "            if i < 20:\n",
    "                print(f\"user_id : {key}, altitude_gained : {value}\")\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    ##############################################################################################################\n",
    "\n",
    "    def query9(self):   \n",
    "        pipeline = [\n",
    "                    {\n",
    "                    \"$sort\": { \"trackpoint_id\": 1 }\n",
    "                },\n",
    "                {\n",
    "                    \"$group\": {\n",
    "                    \"_id\": \"$activity_id\",\n",
    "                    \"list_dates\": {\"$push\": \"$date_time\"},\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"$lookup\": {\n",
    "                    \"from\": \"Activity\",\n",
    "                    \"localField\": \"_id\",\n",
    "                    \"foreignField\": \"activity_id\",\n",
    "                    \"as\": \"activity\"\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"$project\": {\n",
    "                        \"user_id\" : \"$activity.user_info.user_id\",\n",
    "                        \"activity_id\": \"$_id\",\n",
    "                        \"list_dates\": \"$list_dates\"\n",
    "                }\n",
    "                }\n",
    "                ]\n",
    "        result = list(self.db.TrackPoint.aggregate(pipeline))\n",
    "\n",
    "        def is_invalid_timestamp(timestamp1, timestamp2):\n",
    "            time_format = '%Y-%m-%d %H:%M:%S'\n",
    "            dt1 = datetime.strptime(timestamp1, time_format)\n",
    "            dt2 = datetime.strptime(timestamp2, time_format)\n",
    "            return abs((dt2 - dt1).total_seconds()) >= 300 \n",
    "\n",
    "        invalid_activities = {}\n",
    "\n",
    "        for item in result:\n",
    "            user_id = item['user_id'][0]\n",
    "            trackpoints = item['list_dates']\n",
    "            invalid_count = 0\n",
    "            \n",
    "            for i in range(1, len(trackpoints)):\n",
    "                if is_invalid_timestamp(trackpoints[i - 1], trackpoints[i]):\n",
    "                    invalid_count += 1\n",
    "            \n",
    "            if invalid_count > 0:\n",
    "                if user_id in invalid_activities:\n",
    "                    invalid_activities[user_id] += invalid_count\n",
    "                else:\n",
    "                    invalid_activities[user_id] = invalid_count\n",
    "\n",
    "        for user_id, count in invalid_activities.items():\n",
    "            print(f\"user_id: {user_id}, invalid_activities: {count}\")    \n",
    "\n",
    "    ##############################################################################################################\n",
    "\n",
    "    def query10(self):\n",
    "        collection_t = self.db['TrackPoint']\n",
    "\n",
    "        # Define the central coordinate\n",
    "        center_lat = 39.916\n",
    "        center_lon = 116.397\n",
    "\n",
    "        # Max distance in km\n",
    "        max_distance_km = 5\n",
    "        max_dist_degrees = (max_distance_km / 40075) * 360\n",
    "        # Earth's circumference = 40 075\n",
    "        # 360Â°\n",
    "\n",
    "\n",
    "        pipeline = [\n",
    "            {\n",
    "                \"$match\": {\n",
    "                    \"lon\": {\n",
    "                        \"$gte\": center_lon - max_dist_degrees,\n",
    "                        \"$lte\": center_lon + max_dist_degrees\n",
    "                    },\n",
    "                    \"lat\": {\n",
    "                        \"$gte\": center_lat - max_dist_degrees,\n",
    "                        \"$lte\": center_lat + max_dist_degrees\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$lookup\": {\n",
    "                    \"from\": \"Activity\", \n",
    "                    \"localField\": \"activity_id\",  \n",
    "                    \"foreignField\": \"_id\", \n",
    "                    \"as\": \"activity_info\"  \n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$unwind\": \"$activity_info\"\n",
    "            },\n",
    "            {\n",
    "                '$group': {\n",
    "                    '_id': '$activity_info.user_info.user_id'\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        cursor_t = collection_t.aggregate(pipeline)\n",
    "        result_t = list(cursor_t)\n",
    "\n",
    "        if result_t:\n",
    "            print('Users who have tracked an activity in the Forbidden City of Beijing')\n",
    "            for r in result_t:\n",
    "                print(r)\n",
    "        else:\n",
    "            print(\"Error\")\n",
    "\n",
    "    ##############################################################################################################\n",
    "\n",
    "    def query11(self):\n",
    "        pipeline11 = [\n",
    "                {\n",
    "                    \"$match\": {\n",
    "                    \"transportation_mode\":{\"$ne\": \"missing\"} \n",
    "                    \n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"$group\": {\n",
    "                    \"_id\": {\"transportation_mode\":\"$transportation_mode\",\n",
    "                            \"user_id\":\"$user_info.user_id\"},\n",
    "                        \"nb\": { \"$sum\": 1} \n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    '$sort': {\n",
    "                        '_id.user_id': 1,\n",
    "                        'nb': -1\n",
    "                        }\n",
    "                },\n",
    "                {\n",
    "                    \"$group\": {\n",
    "                    \"_id\": \"$_id.user_id\",\n",
    "                        \"most_used_mode\": { '$first': '$_id.transportation_mode'} \n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    '$sort': {\n",
    "                        '_id': 1,\n",
    "                    \n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    '$project': {\n",
    "                        '_id': 0,\n",
    "                        'user_id': '$_id',\n",
    "                        'most_used_transportation_mode': '$most_used_mode'\n",
    "                    }\n",
    "                }\n",
    "                ]\n",
    "        result11 = list(self.db[\"Activity\"].aggregate(pipeline11))\n",
    "\n",
    "        for doc in result11 :\n",
    "            print(\"user_id : \",doc[\"user_id\"], \", most_used_transportation_mode : \", doc[\"most_used_transportation_mode\"])\n",
    "             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are connected to the database: my_db\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "Output query 1 :\n",
      "\n",
      "Tot TrackPoints: 9682005\n",
      "Tot Users: 173\n",
      "Tot Activities: 16048\n",
      "\n",
      "Output query 2 :\n",
      "\n",
      "Average number of activities per user : 92.76878612716763\n",
      "\n",
      "Output query 3 :\n",
      "\n",
      "{'_id': '128', 'count': 2102}\n",
      "{'_id': '153', 'count': 1793}\n",
      "{'_id': '025', 'count': 715}\n",
      "{'_id': '163', 'count': 704}\n",
      "{'_id': '062', 'count': 691}\n",
      "{'_id': '144', 'count': 563}\n",
      "{'_id': '041', 'count': 399}\n",
      "{'_id': '085', 'count': 364}\n",
      "{'_id': '004', 'count': 346}\n",
      "{'_id': '140', 'count': 345}\n",
      "{'_id': '167', 'count': 320}\n",
      "{'_id': '068', 'count': 280}\n",
      "{'_id': '017', 'count': 265}\n",
      "{'_id': '003', 'count': 261}\n",
      "{'_id': '014', 'count': 236}\n",
      "{'_id': '126', 'count': 215}\n",
      "{'_id': '030', 'count': 210}\n",
      "{'_id': '112', 'count': 208}\n",
      "{'_id': '011', 'count': 201}\n",
      "{'_id': '039', 'count': 198}\n",
      "\n",
      "Output query 4 :\n",
      "\n",
      "Users that have taken a taki:\n",
      "'062'\n",
      "'098'\n",
      "'078'\n",
      "'010'\n",
      "'080'\n",
      "'111'\n",
      "'128'\n",
      "'163'\n",
      "'058'\n",
      "'085'\n",
      "\n",
      "Output query 5 :\n",
      "\n",
      "transportation_mode :  train , number of activities :  2\n",
      "transportation_mode :  run , number of activities :  1\n",
      "transportation_mode :  walk , number of activities :  481\n",
      "transportation_mode :  bike , number of activities :  263\n",
      "transportation_mode :  car , number of activities :  419\n",
      "transportation_mode :  subway , number of activities :  133\n",
      "transportation_mode :  bus , number of activities :  199\n",
      "transportation_mode :  boat , number of activities :  1\n",
      "transportation_mode :  taxi , number of activities :  37\n",
      "transportation_mode :  airplane , number of activities :  3\n",
      "\n",
      "Output query 6a :\n",
      "\n",
      "{'_id': 2008, 'count': 5895}\n",
      "\n",
      "Output query 6b :\n",
      "\n",
      "{'_id': 2009, 'total_hours': 11612.423888888889}\n",
      "\n",
      "Output query 7 :\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Connection to my_db-db is closed\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/victoriastasik/Documents/Very_large_distributed_data_volumes_exercise3/code/code.ipynb Cellule 30\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/victoriastasik/Documents/Very_large_distributed_data_volumes_exercise3/code/code.ipynb#X40sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m             program\u001b[39m.\u001b[39mconnection\u001b[39m.\u001b[39mclose_connection()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/victoriastasik/Documents/Very_large_distributed_data_volumes_exercise3/code/code.ipynb#X40sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/victoriastasik/Documents/Very_large_distributed_data_volumes_exercise3/code/code.ipynb#X40sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     main()\n",
      "\u001b[1;32m/Users/victoriastasik/Documents/Very_large_distributed_data_volumes_exercise3/code/code.ipynb Cellule 30\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/victoriastasik/Documents/Very_large_distributed_data_volumes_exercise3/code/code.ipynb#X40sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m program\u001b[39m.\u001b[39mquery6b()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/victoriastasik/Documents/Very_large_distributed_data_volumes_exercise3/code/code.ipynb#X40sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mOutput query 7 :\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/victoriastasik/Documents/Very_large_distributed_data_volumes_exercise3/code/code.ipynb#X40sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m program\u001b[39m.\u001b[39;49mquery7()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/victoriastasik/Documents/Very_large_distributed_data_volumes_exercise3/code/code.ipynb#X40sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mOutput query 8 :\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/victoriastasik/Documents/Very_large_distributed_data_volumes_exercise3/code/code.ipynb#X40sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m program\u001b[39m.\u001b[39mquery8()\n",
      "\u001b[1;32m/Users/victoriastasik/Documents/Very_large_distributed_data_volumes_exercise3/code/code.ipynb Cellule 30\u001b[0m line \u001b[0;36m2\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/victoriastasik/Documents/Very_large_distributed_data_volumes_exercise3/code/code.ipynb#X40sZmlsZQ%3D%3D?line=231'>232</a>\u001b[0m mode \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mwalk\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/victoriastasik/Documents/Very_large_distributed_data_volumes_exercise3/code/code.ipynb#X40sZmlsZQ%3D%3D?line=233'>234</a>\u001b[0m pipeline \u001b[39m=\u001b[39m [\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/victoriastasik/Documents/Very_large_distributed_data_volumes_exercise3/code/code.ipynb#X40sZmlsZQ%3D%3D?line=234'>235</a>\u001b[0m     {\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/victoriastasik/Documents/Very_large_distributed_data_volumes_exercise3/code/code.ipynb#X40sZmlsZQ%3D%3D?line=235'>236</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m$match\u001b[39m\u001b[39m'\u001b[39m: {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/victoriastasik/Documents/Very_large_distributed_data_volumes_exercise3/code/code.ipynb#X40sZmlsZQ%3D%3D?line=261'>262</a>\u001b[0m     }\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/victoriastasik/Documents/Very_large_distributed_data_volumes_exercise3/code/code.ipynb#X40sZmlsZQ%3D%3D?line=262'>263</a>\u001b[0m ]\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/victoriastasik/Documents/Very_large_distributed_data_volumes_exercise3/code/code.ipynb#X40sZmlsZQ%3D%3D?line=264'>265</a>\u001b[0m cursor_a \u001b[39m=\u001b[39m collection_a\u001b[39m.\u001b[39;49maggregate(pipeline)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/victoriastasik/Documents/Very_large_distributed_data_volumes_exercise3/code/code.ipynb#X40sZmlsZQ%3D%3D?line=265'>266</a>\u001b[0m result_a \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(cursor_a)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/victoriastasik/Documents/Very_large_distributed_data_volumes_exercise3/code/code.ipynb#X40sZmlsZQ%3D%3D?line=267'>268</a>\u001b[0m count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pymongo/collection.py:2722\u001b[0m, in \u001b[0;36mCollection.aggregate\u001b[0;34m(self, pipeline, session, let, comment, **kwargs)\u001b[0m\n\u001b[1;32m   2644\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Perform an aggregation using the aggregation framework on this\u001b[39;00m\n\u001b[1;32m   2645\u001b[0m \u001b[39mcollection.\u001b[39;00m\n\u001b[1;32m   2646\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2719\u001b[0m \u001b[39m    https://mongodb.com/docs/manual/reference/command/aggregate\u001b[39;00m\n\u001b[1;32m   2720\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2721\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__database\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39m_tmp_session(session, close\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mas\u001b[39;00m s:\n\u001b[0;32m-> 2722\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_aggregate(\n\u001b[1;32m   2723\u001b[0m         _CollectionAggregationCommand,\n\u001b[1;32m   2724\u001b[0m         pipeline,\n\u001b[1;32m   2725\u001b[0m         CommandCursor,\n\u001b[1;32m   2726\u001b[0m         session\u001b[39m=\u001b[39;49ms,\n\u001b[1;32m   2727\u001b[0m         explicit_session\u001b[39m=\u001b[39;49msession \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   2728\u001b[0m         let\u001b[39m=\u001b[39;49mlet,\n\u001b[1;32m   2729\u001b[0m         comment\u001b[39m=\u001b[39;49mcomment,\n\u001b[1;32m   2730\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   2731\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pymongo/_csot.py:108\u001b[0m, in \u001b[0;36mapply.<locals>.csot_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[39mwith\u001b[39;00m _TimeoutContext(timeout):\n\u001b[1;32m    107\u001b[0m             \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 108\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pymongo/collection.py:2629\u001b[0m, in \u001b[0;36mCollection._aggregate\u001b[0;34m(self, aggregation_command, pipeline, cursor_class, session, explicit_session, let, comment, **kwargs)\u001b[0m\n\u001b[1;32m   2618\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mcomment\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m comment\n\u001b[1;32m   2619\u001b[0m cmd \u001b[39m=\u001b[39m aggregation_command(\n\u001b[1;32m   2620\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   2621\u001b[0m     cursor_class,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2626\u001b[0m     user_fields\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mcursor\u001b[39m\u001b[39m\"\u001b[39m: {\u001b[39m\"\u001b[39m\u001b[39mfirstBatch\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m1\u001b[39m}},\n\u001b[1;32m   2627\u001b[0m )\n\u001b[0;32m-> 2629\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__database\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49m_retryable_read(\n\u001b[1;32m   2630\u001b[0m     cmd\u001b[39m.\u001b[39;49mget_cursor,\n\u001b[1;32m   2631\u001b[0m     cmd\u001b[39m.\u001b[39;49mget_read_preference(session),  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   2632\u001b[0m     session,\n\u001b[1;32m   2633\u001b[0m     retryable\u001b[39m=\u001b[39;49m\u001b[39mnot\u001b[39;49;00m cmd\u001b[39m.\u001b[39;49m_performs_write,\n\u001b[1;32m   2634\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pymongo/_csot.py:108\u001b[0m, in \u001b[0;36mapply.<locals>.csot_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[39mwith\u001b[39;00m _TimeoutContext(timeout):\n\u001b[1;32m    107\u001b[0m             \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 108\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pymongo/mongo_client.py:1535\u001b[0m, in \u001b[0;36mMongoClient._retryable_read\u001b[0;34m(self, func, read_pref, session, address, retryable)\u001b[0m\n\u001b[1;32m   1533\u001b[0m             \u001b[39massert\u001b[39;00m last_error \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1534\u001b[0m             \u001b[39mraise\u001b[39;00m last_error\n\u001b[0;32m-> 1535\u001b[0m         \u001b[39mreturn\u001b[39;00m func(session, server, conn, read_pref)\n\u001b[1;32m   1536\u001b[0m \u001b[39mexcept\u001b[39;00m ServerSelectionTimeoutError:\n\u001b[1;32m   1537\u001b[0m     \u001b[39mif\u001b[39;00m retrying:\n\u001b[1;32m   1538\u001b[0m         \u001b[39m# The application may think the write was never attempted\u001b[39;00m\n\u001b[1;32m   1539\u001b[0m         \u001b[39m# if we raise ServerSelectionTimeoutError on the retry\u001b[39;00m\n\u001b[1;32m   1540\u001b[0m         \u001b[39m# attempt. Raise the original exception instead.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pymongo/aggregation.py:164\u001b[0m, in \u001b[0;36m_AggregationCommand.get_cursor\u001b[0;34m(self, session, server, conn, read_preference)\u001b[0m\n\u001b[1;32m    161\u001b[0m     write_concern \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[39m# Run command.\u001b[39;00m\n\u001b[0;32m--> 164\u001b[0m result \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mcommand(\n\u001b[1;32m    165\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_database\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    166\u001b[0m     cmd,\n\u001b[1;32m    167\u001b[0m     read_preference,\n\u001b[1;32m    168\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_target\u001b[39m.\u001b[39;49mcodec_options,\n\u001b[1;32m    169\u001b[0m     parse_write_concern_error\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    170\u001b[0m     read_concern\u001b[39m=\u001b[39;49mread_concern,\n\u001b[1;32m    171\u001b[0m     write_concern\u001b[39m=\u001b[39;49mwrite_concern,\n\u001b[1;32m    172\u001b[0m     collation\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_collation,\n\u001b[1;32m    173\u001b[0m     session\u001b[39m=\u001b[39;49msession,\n\u001b[1;32m    174\u001b[0m     client\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_database\u001b[39m.\u001b[39;49mclient,\n\u001b[1;32m    175\u001b[0m     user_fields\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_user_fields,\n\u001b[1;32m    176\u001b[0m )\n\u001b[1;32m    178\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result_processor:\n\u001b[1;32m    179\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result_processor(result, conn)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pymongo/helpers.py:315\u001b[0m, in \u001b[0;36m_handle_reauth.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpymongo\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpool\u001b[39;00m \u001b[39mimport\u001b[39;00m Connection\n\u001b[1;32m    314\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 315\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    316\u001b[0m \u001b[39mexcept\u001b[39;00m OperationFailure \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    317\u001b[0m     \u001b[39mif\u001b[39;00m no_reauth:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pymongo/pool.py:960\u001b[0m, in \u001b[0;36mConnection.command\u001b[0;34m(self, dbname, spec, read_preference, codec_options, check, allowable_errors, read_concern, write_concern, parse_write_concern_error, collation, session, client, retryable_write, publish_events, user_fields, exhaust_allowed)\u001b[0m\n\u001b[1;32m    958\u001b[0m \u001b[39m# Catch socket.error, KeyboardInterrupt, etc. and close ourselves.\u001b[39;00m\n\u001b[1;32m    959\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m error:\n\u001b[0;32m--> 960\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_connection_failure(error)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pymongo/pool.py:932\u001b[0m, in \u001b[0;36mConnection.command\u001b[0;34m(self, dbname, spec, read_preference, codec_options, check, allowable_errors, read_concern, write_concern, parse_write_concern_error, collation, session, client, retryable_write, publish_events, user_fields, exhaust_allowed)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_if_not_writable(unacknowledged)\n\u001b[1;32m    931\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 932\u001b[0m     \u001b[39mreturn\u001b[39;00m command(\n\u001b[1;32m    933\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m    934\u001b[0m         dbname,\n\u001b[1;32m    935\u001b[0m         spec,\n\u001b[1;32m    936\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mis_mongos,\n\u001b[1;32m    937\u001b[0m         read_preference,\n\u001b[1;32m    938\u001b[0m         codec_options,\n\u001b[1;32m    939\u001b[0m         session,\n\u001b[1;32m    940\u001b[0m         client,\n\u001b[1;32m    941\u001b[0m         check,\n\u001b[1;32m    942\u001b[0m         allowable_errors,\n\u001b[1;32m    943\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maddress,\n\u001b[1;32m    944\u001b[0m         listeners,\n\u001b[1;32m    945\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_bson_size,\n\u001b[1;32m    946\u001b[0m         read_concern,\n\u001b[1;32m    947\u001b[0m         parse_write_concern_error\u001b[39m=\u001b[39;49mparse_write_concern_error,\n\u001b[1;32m    948\u001b[0m         collation\u001b[39m=\u001b[39;49mcollation,\n\u001b[1;32m    949\u001b[0m         compression_ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompression_context,\n\u001b[1;32m    950\u001b[0m         use_op_msg\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mop_msg_enabled,\n\u001b[1;32m    951\u001b[0m         unacknowledged\u001b[39m=\u001b[39;49munacknowledged,\n\u001b[1;32m    952\u001b[0m         user_fields\u001b[39m=\u001b[39;49muser_fields,\n\u001b[1;32m    953\u001b[0m         exhaust_allowed\u001b[39m=\u001b[39;49mexhaust_allowed,\n\u001b[1;32m    954\u001b[0m         write_concern\u001b[39m=\u001b[39;49mwrite_concern,\n\u001b[1;32m    955\u001b[0m     )\n\u001b[1;32m    956\u001b[0m \u001b[39mexcept\u001b[39;00m (OperationFailure, NotPrimaryError):\n\u001b[1;32m    957\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pymongo/network.py:181\u001b[0m, in \u001b[0;36mcommand\u001b[0;34m(conn, dbname, spec, is_mongos, read_preference, codec_options, session, client, check, allowable_errors, address, listeners, max_bson_size, read_concern, parse_write_concern_error, collation, compression_ctx, use_op_msg, unacknowledged, user_fields, exhaust_allowed, write_concern)\u001b[0m\n\u001b[1;32m    179\u001b[0m     response_doc: _DocumentOut \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mok\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m1\u001b[39m}\n\u001b[1;32m    180\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 181\u001b[0m     reply \u001b[39m=\u001b[39m receive_message(conn, request_id)\n\u001b[1;32m    182\u001b[0m     conn\u001b[39m.\u001b[39mmore_to_come \u001b[39m=\u001b[39m reply\u001b[39m.\u001b[39mmore_to_come\n\u001b[1;32m    183\u001b[0m     unpacked_docs \u001b[39m=\u001b[39m reply\u001b[39m.\u001b[39munpack_response(\n\u001b[1;32m    184\u001b[0m         codec_options\u001b[39m=\u001b[39mcodec_options, user_fields\u001b[39m=\u001b[39muser_fields\n\u001b[1;32m    185\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pymongo/network.py:247\u001b[0m, in \u001b[0;36mreceive_message\u001b[0;34m(conn, request_id, max_message_size)\u001b[0m\n\u001b[1;32m    245\u001b[0m         deadline \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[39m# Ignore the response's request id.\u001b[39;00m\n\u001b[0;32m--> 247\u001b[0m length, _, response_to, op_code \u001b[39m=\u001b[39m _UNPACK_HEADER(_receive_data_on_socket(conn, \u001b[39m16\u001b[39;49m, deadline))\n\u001b[1;32m    248\u001b[0m \u001b[39m# No request_id for exhaust cursor \"getMore\".\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39mif\u001b[39;00m request_id \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pymongo/network.py:328\u001b[0m, in \u001b[0;36m_receive_data_on_socket\u001b[0;34m(conn, length, deadline)\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[39mif\u001b[39;00m _csot\u001b[39m.\u001b[39mget_timeout() \u001b[39mand\u001b[39;00m deadline \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    327\u001b[0m         conn\u001b[39m.\u001b[39mset_conn_timeout(\u001b[39mmax\u001b[39m(deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic(), \u001b[39m0\u001b[39m))\n\u001b[0;32m--> 328\u001b[0m     chunk_length \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mconn\u001b[39m.\u001b[39;49mrecv_into(mv[bytes_read:])\n\u001b[1;32m    329\u001b[0m \u001b[39mexcept\u001b[39;00m BLOCKING_IO_ERRORS:\n\u001b[1;32m    330\u001b[0m     \u001b[39mraise\u001b[39;00m socket\u001b[39m.\u001b[39mtimeout(\u001b[39m\"\u001b[39m\u001b[39mtimed out\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    program = None\n",
    "    try:\n",
    "        program = Task2()\n",
    "\n",
    "        print(\"\\nOutput query 1 :\\n\")\n",
    "        program.query1()\n",
    "        print(\"\\nOutput query 2 :\\n\")\n",
    "        program.query2()\n",
    "        print(\"\\nOutput query 3 :\\n\")\n",
    "        program.query3()\n",
    "        print(\"\\nOutput query 4 :\\n\")\n",
    "        program.query4()\n",
    "        print(\"\\nOutput query 5 :\\n\")\n",
    "        program.query5()\n",
    "        print(\"\\nOutput query 6a :\\n\")\n",
    "        program.query6a()\n",
    "        print(\"\\nOutput query 6b :\\n\")\n",
    "        program.query6b()\n",
    "        print(\"\\nOutput query 7 :\\n\")\n",
    "        program.query7()\n",
    "        print(\"\\nOutput query 8 :\\n\")\n",
    "        program.query8()\n",
    "        print(\"\\nOutput query 9 :\\n\")\n",
    "        program.query9()\n",
    "        print(\"\\nOutput query 10 :\\n\")\n",
    "        program.query10()\n",
    "        print(\"\\nOutput query 11 :\\n\")\n",
    "        program.query11()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"ERROR: Failed to use database:\", e)\n",
    "    finally:\n",
    "        if program:\n",
    "            program.connection.close_connection()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
