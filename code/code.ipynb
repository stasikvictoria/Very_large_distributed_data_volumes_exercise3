{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/victoriastasik/Documents/Very_large_distributed_data_volumes_exercise3/code'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: haversine==2.8.0 in /usr/local/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (2.8.0)\n",
      "Requirement already satisfied: pymongo==4.5.0 in /usr/local/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (4.5.0)\n",
      "Requirement already satisfied: tabulate==0.9.0 in /usr/local/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (0.9.0)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.11/site-packages (from pymongo==4.5.0->-r requirements.txt (line 2)) (2.4.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "from pprint import pprint \n",
    "from pymongo import MongoClient, version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DbConnector.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DbConnector:\n",
    "    \"\"\"\n",
    "    Connects to the MongoDB server on the Ubuntu virtual machine.\n",
    "    Connector needs HOST, USER and PASSWORD to connect.\n",
    "\n",
    "    Example:\n",
    "    HOST = \"tdt4225-00.idi.ntnu.no\" // Your server IP address/domain name\n",
    "    USER = \"testuser\" // This is the user you created and added privileges for\n",
    "    PASSWORD = \"test123\" // The password you set for said user\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 DATABASE='my_db',\n",
    "                 HOST=\"tdt4225-19.idi.ntnu.no\",\n",
    "                 USER=\"team19\",\n",
    "                 PASSWORD=\"team19*\"):\n",
    "        uri = \"mongodb://%s:%s@%s/%s\" % (USER, PASSWORD, HOST, DATABASE)\n",
    "        # Connect to the databases\n",
    "        try:\n",
    "            self.client = MongoClient('mongodb://team19:team19*@tdt4225-19.idi.ntnu.no:27017/my_db')\n",
    "            self.db = self.client[DATABASE]\n",
    "        except Exception as e:\n",
    "            print(\"ERROR: Failed to connect to db:\", e)\n",
    "\n",
    "        # get database information\n",
    "        print(\"You are connected to the database:\", self.db.name)\n",
    "        print(\"-----------------------------------------------\\n\")\n",
    "\n",
    "    def close_connection(self):\n",
    "        # close the cursor\n",
    "        # close the DB connection\n",
    "        self.client.close()\n",
    "        print(\"\\n-----------------------------------------------\")\n",
    "        print(\"Connection to %s-db is closed\" % self.db.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are connected to the database: my_db\n",
      "-----------------------------------------------\n",
      "\n",
      "Created collection:  Collection(Database(MongoClient(host=['tdt4225-19.idi.ntnu.no:27017'], document_class=dict, tz_aware=False, connect=True), 'my_db'), 'Person')\n",
      "[]\n",
      "{'_id': 1,\n",
      " 'courses': [{'code': 'TDT4225',\n",
      "              'name': ' Very Large, Distributed Data Volumes'},\n",
      "             {'code': 'BOI1001', 'name': ' How to become a boi or boierinnaa'}],\n",
      " 'name': 'Bobby'}\n",
      "{'_id': 2,\n",
      " 'courses': [{'code': 'TDT02', 'name': ' Advanced, Distributed Systems'}],\n",
      " 'name': 'Bobby'}\n",
      "{'_id': 3, 'name': 'Bobby'}\n",
      "[]\n",
      "\n",
      "-----------------------------------------------\n",
      "Connection to my_db-db is closed\n"
     ]
    }
   ],
   "source": [
    "class ExampleProgram:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.connection = DbConnector()\n",
    "        self.client = self.connection.client\n",
    "        self.db = self.connection.db\n",
    "\n",
    "    def create_coll(self, collection_name):\n",
    "        collection = self.db.create_collection(collection_name)    \n",
    "        print('Created collection: ', collection)\n",
    "\n",
    "    def insert_documents(self, collection_name):\n",
    "        docs = [\n",
    "            {\n",
    "                \"_id\": 1,\n",
    "                \"name\": \"Bobby\",\n",
    "                \"courses\": \n",
    "                    [\n",
    "                    {'code':'TDT4225', 'name': ' Very Large, Distributed Data Volumes'},\n",
    "                    {'code':'BOI1001', 'name': ' How to become a boi or boierinnaa'}\n",
    "                    ] \n",
    "            },\n",
    "            {\n",
    "                \"_id\": 2,\n",
    "                \"name\": \"Bobby\",\n",
    "                \"courses\": \n",
    "                    [\n",
    "                    {'code':'TDT02', 'name': ' Advanced, Distributed Systems'},\n",
    "                    ] \n",
    "            },\n",
    "            {\n",
    "                \"_id\": 3,\n",
    "                \"name\": \"Bobby\",\n",
    "            }\n",
    "        ]  \n",
    "        collection = self.db[collection_name]\n",
    "        collection.insert_many(docs)\n",
    "        \n",
    "    def fetch_documents(self, collection_name):\n",
    "        collection = self.db[collection_name]\n",
    "        documents = collection.find({})\n",
    "        for doc in documents: \n",
    "            pprint(doc)\n",
    "        \n",
    "\n",
    "    def drop_coll(self, collection_name):\n",
    "        collection = self.db[collection_name]\n",
    "        collection.drop()\n",
    "\n",
    "        \n",
    "    def show_coll(self):\n",
    "        collections = self.client['test'].list_collection_names()\n",
    "        print(collections)\n",
    "         \n",
    "\n",
    "\n",
    "def main():\n",
    "    program = None\n",
    "    try:\n",
    "        program = ExampleProgram()\n",
    "        program.create_coll(collection_name=\"Person\")\n",
    "        program.show_coll()\n",
    "        program.insert_documents(collection_name=\"Person\")\n",
    "        program.fetch_documents(collection_name=\"Person\")\n",
    "        program.drop_coll(collection_name=\"Person\")\n",
    "        # program.drop_coll(collection_name='person')\n",
    "        # program.drop_coll(collection_name='users')\n",
    "        # Check that the table is dropped\n",
    "        program.show_coll()\n",
    "    except Exception as e:\n",
    "        print(\"ERROR: Failed to use database:\", e)\n",
    "    finally:\n",
    "        if program:\n",
    "            program.connection.close_connection()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/victoriastasik/Documents/Very_large_distributed_data_volumes_exercise3/dataset/dataset/Data\n"
     ]
    }
   ],
   "source": [
    "# we go to the Data folder\n",
    "os.chdir(\"..\")\n",
    "path = os.getcwd()\n",
    "os.chdir(\"/Users/victoriastasik/Documents/Very_large_distributed_data_volumes_exercise3/dataset/dataset/Data\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_user_dataframe():\n",
    "    # we get the list of all the diferent directory names (users ids) and we sort the list\n",
    "    usersID =  os.listdir()\n",
    "    usersID.sort()\n",
    "\n",
    "    # we go back to the dataset directory and we read the labeled_ids.txt file\n",
    "    os.chdir(\"..\")\n",
    "    with open('labeled_ids.txt') as f:\n",
    "        labeled_ids = f.readlines()\n",
    "    f.close()\n",
    "    os.chdir(\"/Users/victoriastasik/Documents/Very_large_distributed_data_volumes_exercise3/dataset/dataset/Data\")\n",
    "        \n",
    "    # we delete the \\n in each string\n",
    "    for i in range (0, len(labeled_ids)):\n",
    "        labeled_ids[i] = labeled_ids[i].strip()\n",
    "\n",
    "    # we check if each user has a label or not and we save the info in a list\n",
    "    # the indexes of has_labels and id lists are correponding\n",
    "    has_labels = []\n",
    "    for i in usersID : \n",
    "        if i in labeled_ids : \n",
    "            has_labels.append(True)\n",
    "        else:\n",
    "            has_labels.append(False)\n",
    "\n",
    "    user_table = {'user_id': usersID, 'has_labels': has_labels}\n",
    "    user_dataframe = pd.DataFrame(user_table)\n",
    "    return user_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info_from_labels_txt_file() :\n",
    "    user_id_list = []\n",
    "    transportation_mode_list = []\n",
    "    start_date_time_list = []\n",
    "    end_date_time_list = []\n",
    "\n",
    "    for dirpath, dirnames, filenames in os.walk(os.getcwd()):\n",
    "        for filename in filenames:\n",
    "            # if there is a labels.txt file, we save the info\n",
    "            if filename.endswith('.txt'):\n",
    "                try :\n",
    "                    with open(os.path.join(dirpath, filename)) as f:\n",
    "                        lines = f.readlines()\n",
    "\n",
    "                        # skip the header\n",
    "                        lines = lines[1:]\n",
    "\n",
    "                        for line in lines:\n",
    "                            \n",
    "                            # we get the info of one line\n",
    "                            data = line.split()\n",
    "\n",
    "                            # we save each information into the correct list\n",
    "                            last_directory_name = os.path.basename(dirpath)\n",
    "                            user_id_list.append(last_directory_name)\n",
    "\n",
    "                            transportation_mode_list.append(data[4])\n",
    "\n",
    "                            start_date = data[0]\n",
    "                            start_time = data[1]\n",
    "                            end_date = data[2]\n",
    "                            end_time = data[3]\n",
    "                            start_datetime_str = start_date + \" \" + start_time\n",
    "                            end_datetime_str = end_date + \" \" + end_time\n",
    "                            start_datetime_str = start_datetime_str.replace('/', '-')\n",
    "                            end_datetime_str = end_datetime_str.replace('/', '-')\n",
    "                            combined_start_datetime = datetime.strptime(start_datetime_str, \"%Y-%m-%d %H:%M:%S\")\n",
    "                            combined_end_datetime = datetime.strptime(end_datetime_str, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "                            start_date_time_list.append(combined_start_datetime)\n",
    "                            end_date_time_list.append(combined_end_datetime)\n",
    "                    f.close()\n",
    "\n",
    "                # error handling\n",
    "                except FileNotFoundError:\n",
    "                    print(f\"the file {filename} doesn't exist.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error: {e}\")\n",
    "\n",
    "    return user_id_list, transportation_mode_list, start_date_time_list, end_date_time_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info_from_plt_file() :\n",
    "    activity = 0\n",
    "    activity_id_list = []\n",
    "    user_id_list = []\n",
    "    lat_list = []\n",
    "    long_list = []\n",
    "    altitude_list = []\n",
    "    date_days_list = []\n",
    "    current_date_time_list = []\n",
    "    start_date_time_list = []\n",
    "    end_date_time_list = []\n",
    "\n",
    "    for dirpath, dirnames, filenames in os.walk(os.getcwd()):\n",
    "        for filename in filenames:\n",
    "\n",
    "            # we get the information of each plt file\n",
    "            if filename.endswith('.plt'):\n",
    "                try :\n",
    "                    with open(os.path.join(dirpath, filename)) as f:\n",
    "                        lines = f.readlines()\n",
    "\n",
    "                        # skip the first 6 lines\n",
    "                        lines = lines[6:]\n",
    "\n",
    "                        # check the length of the plt file\n",
    "                        if len(lines) <= 2500:\n",
    "\n",
    "                            # we get the start and end date of each plt file\n",
    "                            start_line= lines[0].split(',')\n",
    "                            start_date = start_line[5]\n",
    "                            start_time = start_line[6]\n",
    "                            start_datetime = start_date + ' ' + start_time\n",
    "                            start_datetime = start_datetime.rstrip('\\n')\n",
    "                            start_datetime = datetime.strptime(start_datetime, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "                            end_line = lines[len(lines)-1].split(',')\n",
    "                            end_date = end_line[5]\n",
    "                            end_time = end_line[6]\n",
    "                            end_datetime = end_date + ' ' + end_time\n",
    "                            end_datetime = end_datetime.rstrip('\\n')\n",
    "                            end_datetime = datetime.strptime(end_datetime, \"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "                            # we save the information of each line of the plt file\n",
    "                            for line in lines:\n",
    "\n",
    "                                data = line.split(',')\n",
    "\n",
    "                                activity_id_list.append(activity)\n",
    "\n",
    "                                parent_directory = os.path.dirname(dirpath)\n",
    "                                directory_name = os.path.basename(parent_directory) \n",
    "                                user_id_list.append(directory_name)\n",
    "\n",
    "                                lat_list.append(float(data[0]))\n",
    "                                long_list.append(float(data[1]))\n",
    "                                altitude_list.append(int(float(data[3])))\n",
    "                                date_days_list.append(float(data[4]))\n",
    "\n",
    "                                date = data[5]\n",
    "                                time = data[6]\n",
    "                                datetime_draft = date + ' ' + time\n",
    "                                datetime_draft = datetime_draft.rstrip('\\n')\n",
    "                                combined_datetime = datetime.strptime(datetime_draft, \"%Y-%m-%d %H:%M:%S\")\n",
    "                                current_date_time_list.append(combined_datetime)\n",
    "\n",
    "                                start_date_time_list.append(start_datetime)\n",
    "                                end_date_time_list.append(end_datetime)\n",
    "\n",
    "                    f.close()\n",
    "                    activity +=1\n",
    "                  \n",
    "                except FileNotFoundError:\n",
    "                    print(f\"the file {filename} doesn't exist.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error: {e}\")\n",
    "                    \n",
    "    return activity_id_list, user_id_list, lat_list, long_list, altitude_list, date_days_list, current_date_time_list, start_date_time_list, end_date_time_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_activity_and_trackpoint_dataframe():    \n",
    "    # getting info from txt files\n",
    "    user_id_list, transportation_mode_list, start_date_time_list, end_date_time_list = get_info_from_labels_txt_file()\n",
    "    labels_txt = {'user_id': user_id_list, 'transportation_mode': transportation_mode_list, 'start_datetime': start_date_time_list, 'end_datetime': end_date_time_list}\n",
    "    labels_txt_df = pd.DataFrame(labels_txt)\n",
    "\n",
    "    # getting info from plt files\n",
    "    activity_id_list, user_id_list_2, lat_list, long_list, altitude_list, date_days_list, current_date_time_list, start_date_time_list2, end_date_time_list2 = get_info_from_plt_file()\n",
    "    plt = {'activity_id': activity_id_list, 'user_id': user_id_list_2, 'lat': lat_list, 'long': long_list, 'altitude': altitude_list, 'date_days': date_days_list, \n",
    "           'current_date_time': current_date_time_list, 'start_datetime': start_date_time_list2, 'end_datetime': end_date_time_list2}\n",
    "    plt_df = pd.DataFrame(plt)\n",
    "\n",
    "    # merging both dataframes\n",
    "    merged_df = pd.merge(plt_df, labels_txt_df, on=['user_id', 'start_datetime', 'end_datetime'], how='left')\n",
    "\n",
    "    # creating activity table\n",
    "    activity_table = merged_df[['activity_id','user_id', 'transportation_mode', 'start_datetime', 'end_datetime']]\n",
    "    activity_table = activity_table.fillna(\"missing\")\n",
    "    activity_table['start_datetime'] = activity_table['start_datetime'].astype(str) # converting into string to be able to insert into the sql table\n",
    "    activity_table['end_datetime'] = activity_table['end_datetime'].astype(str)\n",
    "    activity_table = activity_table.drop_duplicates()\n",
    "\n",
    "    # creating trackpoint table\n",
    "    trackpoint_table = merged_df[['activity_id','lat', 'long', 'altitude', 'date_days', 'current_date_time']]\n",
    "    trackpoint_table.rename(columns={'current_date_time': 'date_time'}, inplace=True)\n",
    "    trackpoint_table['id'] = range(1, len(trackpoint_table) + 1)\n",
    "    trackpoint_table = trackpoint_table[['id'] + [col for col in trackpoint_table.columns if col != 'id']]\n",
    "    trackpoint_table['date_time'] = trackpoint_table['date_time'].astype(str)\n",
    "\n",
    "    return activity_table, trackpoint_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Task1:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.connection = DbConnector()\n",
    "        self.client = self.connection.client\n",
    "        self.db = self.connection.db\n",
    "\n",
    "    def create_coll(self, collection_name):\n",
    "        collection = self.db.create_collection(collection_name)    \n",
    "        print('Created collection: ', collection)\n",
    "\n",
    "    def insert_activity_data(self, user_table, activity_table):\n",
    "        merged_df = pd.merge(user_table, activity_table, on=['user_id'])\n",
    "\n",
    "        result_list = []\n",
    "        for index, row in merged_df.iterrows():\n",
    "            user_info = {'user_id': row['user_id'], 'has_labels': row['has_labels']}\n",
    "            entry = {\n",
    "                '_id': index,\n",
    "                'activity_id': row['activity_id'],\n",
    "                'user_info': user_info,\n",
    "                'transportation_mode': row['transportation_mode'],\n",
    "                'start_datetime': row['start_datetime'],\n",
    "                'end_datetime': row['end_datetime']\n",
    "            }\n",
    "            result_list.append(entry)\n",
    "        \n",
    "        collection = self.db[\"Activity\"]\n",
    "        collection.insert_many(result_list)\n",
    "\n",
    "    def insert_trackpoint_data(self, activity_table, trackpoint_table):\n",
    "        \n",
    "        result_list = []\n",
    "        for index, row in trackpoint_table.iterrows():\n",
    "            entry = {\n",
    "                '_id': row['id'],\n",
    "                'activity_id': row['activity_id'],\n",
    "                'lat': row['lat'],\n",
    "                'lon': row['long'],\n",
    "                'altitude': row['altitude'],\n",
    "                'date_days': row['date_days'],\n",
    "                'date_time': row['date_time']\n",
    "            }\n",
    "            result_list.append(entry)\n",
    "        \n",
    "        collection = self.db[\"TrackPoint\"]\n",
    "        collection.insert_many(result_list)\n",
    "\n",
    "    def compute_aggregated_query(self, collection_name, pipeline):\n",
    "        collection = self.db[collection_name]\n",
    "        result = collection.aggregate(pipeline)\n",
    "        for i in result: \n",
    "            pprint(i)\n",
    "        \n",
    "    def fetch_documents(self, collection_name):\n",
    "        collection = self.db[collection_name]\n",
    "        documents = collection.find({})\n",
    "        for doc in documents: \n",
    "            pprint(doc)\n",
    "        \n",
    "    def drop_coll(self, collection_name):\n",
    "        collection = self.db[collection_name]\n",
    "        collection.drop()\n",
    "\n",
    "        \n",
    "    def show_coll(self):\n",
    "        collections = self.client['my_db'].list_collection_names()\n",
    "        print(collections)         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are connected to the database: my_db\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Connection to my_db-db is closed\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    program = None\n",
    "    try:\n",
    "        activity_table, trackpoint_table = creating_activity_and_trackpoint_dataframe()\n",
    "        user_table = creating_user_dataframe()\n",
    "        \n",
    "        program = Task1()\n",
    "\n",
    "        program.drop_coll(collection_name=\"Activity\")\n",
    "        program.drop_coll(collection_name=\"TrackPoint\")\n",
    "\n",
    "        program.create_coll(collection_name=\"Activity\")\n",
    "        program.create_coll(collection_name=\"TrackPoint\")\n",
    "        program.show_coll()\n",
    "        \n",
    "        program.insert_activity_data(user_table, activity_table)\n",
    "        program.insert_trackpoint_data(activity_table, trackpoint_table)\n",
    "\n",
    "        program.fetch_documents(collection_name=\"Activity\")\n",
    "        program.fetch_documents(collection_name=\"TrackPoint\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"ERROR: Failed to use database:\", e)\n",
    "    finally:\n",
    "        if program:\n",
    "            program.connection.close_connection()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are connected to the database: my_db\n",
      "-----------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "connection = DbConnector()\n",
    "client = connection.client\n",
    "db = connection.db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': '128', 'count': 2102}\n",
      "{'_id': '153', 'count': 1793}\n",
      "{'_id': '025', 'count': 715}\n",
      "{'_id': '163', 'count': 704}\n",
      "{'_id': '062', 'count': 691}\n",
      "{'_id': '144', 'count': 563}\n",
      "{'_id': '041', 'count': 399}\n",
      "{'_id': '085', 'count': 364}\n",
      "{'_id': '004', 'count': 346}\n",
      "{'_id': '140', 'count': 345}\n",
      "{'_id': '167', 'count': 320}\n",
      "{'_id': '068', 'count': 280}\n",
      "{'_id': '017', 'count': 265}\n",
      "{'_id': '003', 'count': 261}\n",
      "{'_id': '014', 'count': 236}\n",
      "{'_id': '126', 'count': 215}\n",
      "{'_id': '030', 'count': 210}\n",
      "{'_id': '112', 'count': 208}\n",
      "{'_id': '011', 'count': 201}\n",
      "{'_id': '039', 'count': 198}\n"
     ]
    }
   ],
   "source": [
    "pipeline = [\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": \"$user_info.user_id\",\n",
    "            \"count\": { \"$sum\": 1 }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$sort\": {\"count\": -1}\n",
    "    },\n",
    "    {\n",
    "        \"$limit\": 20\n",
    "    }\n",
    "]\n",
    "result = list(db.Activity.aggregate(pipeline))\n",
    "\n",
    "for doc in result:\n",
    "    pprint(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 6a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 2008, 'count': 5895}\n"
     ]
    }
   ],
   "source": [
    "pipeline = [\n",
    "    {\n",
    "        \"$project\": {\n",
    "            \"year\": { \"$year\": { \"$dateFromString\": { \"dateString\": \"$start_datetime\" } }}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": \"$year\",\n",
    "            \"count\": { \"$sum\": 1 }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$sort\": { \"count\": -1 }\n",
    "    },\n",
    "    {\n",
    "        \"$limit\": 1\n",
    "    }\n",
    "]\n",
    "\n",
    "result = list(db.Activity.aggregate(pipeline))\n",
    "\n",
    "for doc in result:\n",
    "    pprint(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 6b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 2009, 'total_hours': 11612.423888888889}\n"
     ]
    }
   ],
   "source": [
    "pipeline = [\n",
    "    {\n",
    "        \"$addFields\": {\n",
    "            \"start_datetime\": {\n",
    "                \"$dateFromString\": {\n",
    "                    \"dateString\": \"$start_datetime\",\n",
    "                    \"format\": \"%Y-%m-%d %H:%M:%S\"\n",
    "                }\n",
    "            },\n",
    "            \"end_datetime\": {\n",
    "                \"$dateFromString\": {\n",
    "                    \"dateString\": \"$end_datetime\",\n",
    "                    \"format\": \"%Y-%m-%d %H:%M:%S\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$project\": {\n",
    "            \"year\": { \"$year\": \"$start_datetime\" },\n",
    "            \"duration\": {\n",
    "                \"$divide\": [\n",
    "                    { \"$subtract\": [\"$end_datetime\", \"$start_datetime\"] },\n",
    "                    1000 * 60 * 60\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": \"$year\",\n",
    "            \"total_hours\": { \"$sum\": \"$duration\" }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$sort\": { \"total_hours\": -1 }\n",
    "    },\n",
    "    {\n",
    "        \"$limit\": 1\n",
    "    }\n",
    "]\n",
    "\n",
    "result = list(db.Activity.aggregate(pipeline))\n",
    "\n",
    "for doc in result:\n",
    "    pprint(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = [\n",
    "    {\n",
    "        \"$lookup\": {\n",
    "            \"from\": \"TrackPoint\",\n",
    "            \"localField\": \"activity_id\",\n",
    "            \"foreignField\": \"activity_id\",\n",
    "            \"as\": \"trackpoints\",\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"$unwind\": \"$trackpoints\",\n",
    "    },\n",
    "    {\n",
    "        \"$sort\": {\"user_info.user_id\": 1, \"start_datetime\": 1},\n",
    "    },\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": \"$user_info.user_id\",\n",
    "            \"activities\": {\"$push\": \"$$ROOT\"},\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"$unwind\": \"$activities\",\n",
    "    },\n",
    "    {\n",
    "        \"$project\": {\n",
    "            \"user_id\": \"$_id\",\n",
    "            \"activity\": \"$activities\",\n",
    "            \"next_activity\": {\"$arrayElemAt\": [\"$activities\", 1]},\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"$addFields\": {\n",
    "            \"time_difference\": {\n",
    "                \"$divide\": [\n",
    "                    {\n",
    "                        \"$subtract\": [\n",
    "                            {\n",
    "                                \"$dateFromString\": {\n",
    "                                    \"dateString\": \"$next_activity.trackpoints.date_time\",\n",
    "                                }\n",
    "                            },\n",
    "                            {\n",
    "                                \"$dateFromString\": {\n",
    "                                    \"dateString\": \"$activity.trackpoints.date_time\",\n",
    "                                }\n",
    "                            },\n",
    "                        ]\n",
    "                    },\n",
    "                    1000 * 60,\n",
    "                ],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"$match\": {\n",
    "            \"time_difference\": {\"$gte\": 5},\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": \"$user_id\",\n",
    "            \"invalid_activity_count\": {\"$sum\": 1},\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "result = list(db.Activity.aggregate(pipeline))\n",
    "\n",
    "for doc in result:\n",
    "    pprint(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.close_connection()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
