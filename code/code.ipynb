{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/victoriastasik/Documents/Very_large_distributed_data_volumes_exercise3/code'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: haversine==2.8.0 in /usr/local/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (2.8.0)\n",
      "Requirement already satisfied: pymongo==4.5.0 in /usr/local/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (4.5.0)\n",
      "Requirement already satisfied: tabulate==0.9.0 in /usr/local/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (0.9.0)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.11/site-packages (from pymongo==4.5.0->-r requirements.txt (line 2)) (2.4.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint \n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DbConnector.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DbConnector:\n",
    "    \"\"\"\n",
    "    Connects to the MongoDB server on the Ubuntu virtual machine.\n",
    "    Connector needs HOST, USER and PASSWORD to connect.\n",
    "\n",
    "    Example:\n",
    "    HOST = \"tdt4225-00.idi.ntnu.no\" // Your server IP address/domain name\n",
    "    USER = \"testuser\" // This is the user you created and added privileges for\n",
    "    PASSWORD = \"test123\" // The password you set for said user\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 DATABASE='my_db',\n",
    "                 HOST=\"tdt4225-19.idi.ntnu.no\",\n",
    "                 USER=\"team19\",\n",
    "                 PASSWORD=\"team19*\"):\n",
    "        uri = \"mongodb://%s:%s@%s/%s\" % (USER, PASSWORD, HOST, DATABASE)\n",
    "        # Connect to the databases\n",
    "        try:\n",
    "            self.client = MongoClient('mongodb://team19:team19*@tdt4225-19.idi.ntnu.no:27017/my_db')\n",
    "            self.db = self.client[DATABASE]\n",
    "        except Exception as e:\n",
    "            print(\"ERROR: Failed to connect to db:\", e)\n",
    "\n",
    "        # get database information\n",
    "        print(\"You are connected to the database:\", self.db.name)\n",
    "        print(\"-----------------------------------------------\\n\")\n",
    "\n",
    "    def close_connection(self):\n",
    "        # close the cursor\n",
    "        # close the DB connection\n",
    "        self.client.close()\n",
    "        print(\"\\n-----------------------------------------------\")\n",
    "        print(\"Connection to %s-db is closed\" % self.db.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are connected to the database: my_db\n",
      "-----------------------------------------------\n",
      "\n",
      "Created collection:  Collection(Database(MongoClient(host=['tdt4225-19.idi.ntnu.no:27017'], document_class=dict, tz_aware=False, connect=True), 'my_db'), 'Person')\n",
      "[]\n",
      "{'_id': 1,\n",
      " 'courses': [{'code': 'TDT4225',\n",
      "              'name': ' Very Large, Distributed Data Volumes'},\n",
      "             {'code': 'BOI1001', 'name': ' How to become a boi or boierinnaa'}],\n",
      " 'name': 'Bobby'}\n",
      "{'_id': 2,\n",
      " 'courses': [{'code': 'TDT02', 'name': ' Advanced, Distributed Systems'}],\n",
      " 'name': 'Bobby'}\n",
      "{'_id': 3, 'name': 'Bobby'}\n",
      "[]\n",
      "\n",
      "-----------------------------------------------\n",
      "Connection to my_db-db is closed\n"
     ]
    }
   ],
   "source": [
    "class ExampleProgram:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.connection = DbConnector()\n",
    "        self.client = self.connection.client\n",
    "        self.db = self.connection.db\n",
    "\n",
    "    def create_coll(self, collection_name):\n",
    "        collection = self.db.create_collection(collection_name)    \n",
    "        print('Created collection: ', collection)\n",
    "\n",
    "    def insert_documents(self, collection_name):\n",
    "        docs = [\n",
    "            {\n",
    "                \"_id\": 1,\n",
    "                \"name\": \"Bobby\",\n",
    "                \"courses\": \n",
    "                    [\n",
    "                    {'code':'TDT4225', 'name': ' Very Large, Distributed Data Volumes'},\n",
    "                    {'code':'BOI1001', 'name': ' How to become a boi or boierinnaa'}\n",
    "                    ] \n",
    "            },\n",
    "            {\n",
    "                \"_id\": 2,\n",
    "                \"name\": \"Bobby\",\n",
    "                \"courses\": \n",
    "                    [\n",
    "                    {'code':'TDT02', 'name': ' Advanced, Distributed Systems'},\n",
    "                    ] \n",
    "            },\n",
    "            {\n",
    "                \"_id\": 3,\n",
    "                \"name\": \"Bobby\",\n",
    "            }\n",
    "        ]  \n",
    "        collection = self.db[collection_name]\n",
    "        collection.insert_many(docs)\n",
    "        \n",
    "    def fetch_documents(self, collection_name):\n",
    "        collection = self.db[collection_name]\n",
    "        documents = collection.find({})\n",
    "        for doc in documents: \n",
    "            pprint(doc)\n",
    "        \n",
    "\n",
    "    def drop_coll(self, collection_name):\n",
    "        collection = self.db[collection_name]\n",
    "        collection.drop()\n",
    "\n",
    "        \n",
    "    def show_coll(self):\n",
    "        collections = self.client['test'].list_collection_names()\n",
    "        print(collections)\n",
    "         \n",
    "\n",
    "\n",
    "def main():\n",
    "    program = None\n",
    "    try:\n",
    "        program = ExampleProgram()\n",
    "        program.create_coll(collection_name=\"Person\")\n",
    "        program.show_coll()\n",
    "        program.insert_documents(collection_name=\"Person\")\n",
    "        program.fetch_documents(collection_name=\"Person\")\n",
    "        program.drop_coll(collection_name=\"Person\")\n",
    "        # program.drop_coll(collection_name='person')\n",
    "        # program.drop_coll(collection_name='users')\n",
    "        # Check that the table is dropped\n",
    "        program.show_coll()\n",
    "    except Exception as e:\n",
    "        print(\"ERROR: Failed to use database:\", e)\n",
    "    finally:\n",
    "        if program:\n",
    "            program.connection.close_connection()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/victoriastasik/Documents/Very_large_distributed_data_volumes_exercise3/dataset/dataset/Data\n"
     ]
    }
   ],
   "source": [
    "# we go to the Data folder\n",
    "os.chdir(\"..\")\n",
    "path = os.getcwd()\n",
    "os.chdir(\"/Users/victoriastasik/Documents/Very_large_distributed_data_volumes_exercise3/dataset/dataset/Data\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_user_dataframe():\n",
    "    # we get the list of all the diferent directory names (users ids) and we sort the list\n",
    "    usersID =  os.listdir()\n",
    "    usersID.sort()\n",
    "\n",
    "    # we go back to the dataset directory and we read the labeled_ids.txt file\n",
    "    os.chdir(\"..\")\n",
    "    with open('labeled_ids.txt') as f:\n",
    "        labeled_ids = f.readlines()\n",
    "    f.close()\n",
    "    os.chdir(\"/Users/victoriastasik/Documents/Very_large_distributed_data_volumes_exercise3/dataset/dataset/Data\")\n",
    "        \n",
    "    # we delete the \\n in each string\n",
    "    for i in range (0, len(labeled_ids)):\n",
    "        labeled_ids[i] = labeled_ids[i].strip()\n",
    "\n",
    "    # we check if each user has a label or not and we save the info in a list\n",
    "    # the indexes of has_labels and id lists are correponding\n",
    "    has_labels = []\n",
    "    for i in usersID : \n",
    "        if i in labeled_ids : \n",
    "            has_labels.append(True)\n",
    "        else:\n",
    "            has_labels.append(False)\n",
    "\n",
    "    user_table = {'user_id': usersID, 'has_labels': has_labels}\n",
    "    user_dataframe = pd.DataFrame(user_table)\n",
    "    return user_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info_from_labels_txt_file() :\n",
    "    user_id_list = []\n",
    "    transportation_mode_list = []\n",
    "    start_date_time_list = []\n",
    "    end_date_time_list = []\n",
    "\n",
    "    for dirpath, dirnames, filenames in os.walk(os.getcwd()):\n",
    "        for filename in filenames:\n",
    "            # if there is a labels.txt file, we save the info\n",
    "            if filename.endswith('.txt'):\n",
    "                try :\n",
    "                    with open(os.path.join(dirpath, filename)) as f:\n",
    "                        lines = f.readlines()\n",
    "\n",
    "                        # skip the header\n",
    "                        lines = lines[1:]\n",
    "\n",
    "                        for line in lines:\n",
    "                            \n",
    "                            # we get the info of one line\n",
    "                            data = line.split()\n",
    "\n",
    "                            # we save each information into the correct list\n",
    "                            last_directory_name = os.path.basename(dirpath)\n",
    "                            user_id_list.append(last_directory_name)\n",
    "\n",
    "                            transportation_mode_list.append(data[4])\n",
    "\n",
    "                            start_date = data[0]\n",
    "                            start_time = data[1]\n",
    "                            end_date = data[2]\n",
    "                            end_time = data[3]\n",
    "                            start_datetime_str = start_date + \" \" + start_time\n",
    "                            end_datetime_str = end_date + \" \" + end_time\n",
    "                            start_datetime_str = start_datetime_str.replace('/', '-')\n",
    "                            end_datetime_str = end_datetime_str.replace('/', '-')\n",
    "                            combined_start_datetime = datetime.strptime(start_datetime_str, \"%Y-%m-%d %H:%M:%S\")\n",
    "                            combined_end_datetime = datetime.strptime(end_datetime_str, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "                            start_date_time_list.append(combined_start_datetime)\n",
    "                            end_date_time_list.append(combined_end_datetime)\n",
    "                    f.close()\n",
    "\n",
    "                # error handling\n",
    "                except FileNotFoundError:\n",
    "                    print(f\"the file {filename} doesn't exist.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error: {e}\")\n",
    "\n",
    "    return user_id_list, transportation_mode_list, start_date_time_list, end_date_time_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info_from_plt_file() :\n",
    "    activity = 0\n",
    "    activity_id_list = []\n",
    "    user_id_list = []\n",
    "    lat_list = []\n",
    "    long_list = []\n",
    "    altitude_list = []\n",
    "    date_days_list = []\n",
    "    current_date_time_list = []\n",
    "    start_date_time_list = []\n",
    "    end_date_time_list = []\n",
    "\n",
    "    for dirpath, dirnames, filenames in os.walk(os.getcwd()):\n",
    "        for filename in filenames:\n",
    "\n",
    "            # we get the information of each plt file\n",
    "            if filename.endswith('.plt'):\n",
    "                try :\n",
    "                    with open(os.path.join(dirpath, filename)) as f:\n",
    "                        lines = f.readlines()\n",
    "\n",
    "                        # skip the first 6 lines\n",
    "                        lines = lines[6:]\n",
    "\n",
    "                        # check the length of the plt file\n",
    "                        if len(lines) <= 2500:\n",
    "\n",
    "                            # we get the start and end date of each plt file\n",
    "                            start_line= lines[0].split(',')\n",
    "                            start_date = start_line[5]\n",
    "                            start_time = start_line[6]\n",
    "                            start_datetime = start_date + ' ' + start_time\n",
    "                            start_datetime = start_datetime.rstrip('\\n')\n",
    "                            start_datetime = datetime.strptime(start_datetime, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "                            end_line = lines[len(lines)-1].split(',')\n",
    "                            end_date = end_line[5]\n",
    "                            end_time = end_line[6]\n",
    "                            end_datetime = end_date + ' ' + end_time\n",
    "                            end_datetime = end_datetime.rstrip('\\n')\n",
    "                            end_datetime = datetime.strptime(end_datetime, \"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "                            # we save the information of each line of the plt file\n",
    "                            for line in lines:\n",
    "\n",
    "                                data = line.split(',')\n",
    "\n",
    "                                activity_id_list.append(activity)\n",
    "\n",
    "                                parent_directory = os.path.dirname(dirpath)\n",
    "                                directory_name = os.path.basename(parent_directory) \n",
    "                                user_id_list.append(directory_name)\n",
    "\n",
    "                                lat_list.append(float(data[0]))\n",
    "                                long_list.append(float(data[1]))\n",
    "                                altitude_list.append(int(float(data[3])))\n",
    "                                date_days_list.append(float(data[4]))\n",
    "\n",
    "                                date = data[5]\n",
    "                                time = data[6]\n",
    "                                datetime_draft = date + ' ' + time\n",
    "                                datetime_draft = datetime_draft.rstrip('\\n')\n",
    "                                combined_datetime = datetime.strptime(datetime_draft, \"%Y-%m-%d %H:%M:%S\")\n",
    "                                current_date_time_list.append(combined_datetime)\n",
    "\n",
    "                                start_date_time_list.append(start_datetime)\n",
    "                                end_date_time_list.append(end_datetime)\n",
    "\n",
    "                    f.close()\n",
    "                    activity +=1\n",
    "                  \n",
    "                except FileNotFoundError:\n",
    "                    print(f\"the file {filename} doesn't exist.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error: {e}\")\n",
    "                    \n",
    "    return activity_id_list, user_id_list, lat_list, long_list, altitude_list, date_days_list, current_date_time_list, start_date_time_list, end_date_time_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_activity_and_trackpoint_dataframe():    \n",
    "    # getting info from txt files\n",
    "    user_id_list, transportation_mode_list, start_date_time_list, end_date_time_list = get_info_from_labels_txt_file()\n",
    "    labels_txt = {'user_id': user_id_list, 'transportation_mode': transportation_mode_list, 'start_datetime': start_date_time_list, 'end_datetime': end_date_time_list}\n",
    "    labels_txt_df = pd.DataFrame(labels_txt)\n",
    "\n",
    "    # getting info from plt files\n",
    "    activity_id_list, user_id_list_2, lat_list, long_list, altitude_list, date_days_list, current_date_time_list, start_date_time_list2, end_date_time_list2 = get_info_from_plt_file()\n",
    "    plt = {'activity_id': activity_id_list, 'user_id': user_id_list_2, 'lat': lat_list, 'long': long_list, 'altitude': altitude_list, 'date_days': date_days_list, \n",
    "           'current_date_time': current_date_time_list, 'start_datetime': start_date_time_list2, 'end_datetime': end_date_time_list2}\n",
    "    plt_df = pd.DataFrame(plt)\n",
    "\n",
    "    # merging both dataframes\n",
    "    merged_df = pd.merge(plt_df, labels_txt_df, on=['user_id', 'start_datetime', 'end_datetime'], how='left')\n",
    "\n",
    "    # creating activity table\n",
    "    activity_table = merged_df[['activity_id','user_id', 'transportation_mode', 'start_datetime', 'end_datetime']]\n",
    "    activity_table = activity_table.fillna(\"missing\")\n",
    "    activity_table['start_datetime'] = activity_table['start_datetime'].astype(str) # converting into string to be able to insert into the sql table\n",
    "    activity_table['end_datetime'] = activity_table['end_datetime'].astype(str)\n",
    "    activity_table = activity_table.drop_duplicates()\n",
    "\n",
    "    # creating trackpoint table\n",
    "    trackpoint_table = merged_df[['activity_id','lat', 'long', 'altitude', 'date_days', 'current_date_time']]\n",
    "    trackpoint_table.rename(columns={'current_date_time': 'date_time'}, inplace=True)\n",
    "    trackpoint_table['id'] = range(1, len(trackpoint_table) + 1)\n",
    "    trackpoint_table = trackpoint_table[['id'] + [col for col in trackpoint_table.columns if col != 'id']]\n",
    "    trackpoint_table['date_time'] = trackpoint_table['date_time'].astype(str)\n",
    "\n",
    "    return activity_table, trackpoint_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Task1:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.connection = DbConnector()\n",
    "        self.client = self.connection.client\n",
    "        self.db = self.connection.db\n",
    "\n",
    "    def create_coll(self, collection_name):\n",
    "        collection = self.db.create_collection(collection_name)    \n",
    "        print('Created collection: ', collection)\n",
    "\n",
    "    def insert_activity_data(self, user_table, activity_table):\n",
    "        merged_df = pd.merge(user_table, activity_table, on=['user_id'])\n",
    "\n",
    "        result_list = []\n",
    "        for index, row in merged_df.iterrows():\n",
    "            user_info = {'user_id': row['user_id'], 'has_labels': row['has_labels']}\n",
    "            entry = {\n",
    "                '_id': index,\n",
    "                'activity_id': row['activity_id'],\n",
    "                'user_info': user_info,\n",
    "                'transportation_mode': row['transportation_mode'],\n",
    "                'start_datetime': row['start_datetime'],\n",
    "                'end_datetime': row['end_datetime']\n",
    "            }\n",
    "            result_list.append(entry)\n",
    "        \n",
    "        collection = self.db[\"Activity\"]\n",
    "        collection.insert_many(result_list)\n",
    "\n",
    "    def insert_trackpoint_data(self, trackpoint_table):\n",
    "        \n",
    "        result_list = []\n",
    "        for index, row in trackpoint_table.iterrows():\n",
    "            entry = {\n",
    "                '_id': row['id'],\n",
    "                'activity_id': row['activity_id'],\n",
    "                'lat': row['lat'],\n",
    "                'lon': row['long'],\n",
    "                'altitude': row['altitude'],\n",
    "                'date_days': row['date_days'],\n",
    "                'date_time': row['date_time']\n",
    "            }\n",
    "            result_list.append(entry)\n",
    "        \n",
    "        collection = self.db[\"TrackPoint\"]\n",
    "        collection.insert_many(result_list)\n",
    "\n",
    "    def compute_aggregated_query(self, collection_name, pipeline):\n",
    "        collection = self.db[collection_name]\n",
    "        result = collection.aggregate(pipeline)\n",
    "        for i in result: \n",
    "            pprint(i)\n",
    "        \n",
    "    def fetch_documents(self, collection_name):\n",
    "        collection = self.db[collection_name]\n",
    "        documents = collection.find({})\n",
    "        for doc in documents: \n",
    "            pprint(doc)\n",
    "        \n",
    "    def drop_coll(self, collection_name):\n",
    "        collection = self.db[collection_name]\n",
    "        collection.drop()\n",
    "\n",
    "        \n",
    "    def show_coll(self):\n",
    "        collections = self.client['my_db'].list_collection_names()\n",
    "        print(collections)         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are connected to the database: my_db\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Connection to my_db-db is closed\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    program = None\n",
    "    try:\n",
    "        activity_table, trackpoint_table = creating_activity_and_trackpoint_dataframe()\n",
    "        user_table = creating_user_dataframe()\n",
    "        \n",
    "        program = Task1()\n",
    "\n",
    "        program.drop_coll(collection_name=\"Activity\")\n",
    "        program.drop_coll(collection_name=\"TrackPoint\")\n",
    "\n",
    "        program.create_coll(collection_name=\"Activity\")\n",
    "        program.create_coll(collection_name=\"TrackPoint\")\n",
    "        program.show_coll()\n",
    "        \n",
    "        program.insert_activity_data(user_table, activity_table)\n",
    "        program.insert_trackpoint_data(trackpoint_table)\n",
    "\n",
    "        program.fetch_documents(collection_name=\"Activity\")\n",
    "        program.fetch_documents(collection_name=\"TrackPoint\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"ERROR: Failed to use database:\", e)\n",
    "    finally:\n",
    "        if program:\n",
    "            program.connection.close_connection()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def haversine_distance(coord1, coord2):\n",
    "    # Radius of the Earth in kilometers\n",
    "    radius = 6371\n",
    "\n",
    "    # Extract longitude and latitude from the coordinate tuples\n",
    "    lon1, lat1 = coord1\n",
    "    lon2, lat2 = coord2\n",
    "\n",
    "    # Convert latitude and longitude from degrees to radians\n",
    "    lon1, lat1, lon2, lat2 = map(math.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # Haversine formula\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2\n",
    "    c = 2 * math.asin(math.sqrt(a))\n",
    "\n",
    "    # Calculate the distance\n",
    "    distance = radius * c\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Task2:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.connection = DbConnector()\n",
    "        self.client = self.connection.client\n",
    "        self.db = self.connection.db\n",
    "\n",
    "    ##############################################################################################################\n",
    "\n",
    "    def query1(self):\n",
    "        collection_a = self.db['Activity']\n",
    "        collection_t = self.db['TrackPoint']\n",
    "\n",
    "        pipeline_t = [\n",
    "        {\n",
    "            '$group': {\n",
    "                '_id': None,\n",
    "                'count': {'$sum': 1}\n",
    "            }\n",
    "        }]\n",
    "\n",
    "        pipeline_a = [\n",
    "        {\n",
    "            \"$group\": {\n",
    "                \"_id\": None,\n",
    "                \"user_ids\": {\"$addToSet\": \"$user_info.user_id\"},\n",
    "                \"activity_ids\": {\"$addToSet\": \"$activity_id\"}\n",
    "            }   \n",
    "        },\n",
    "        {\n",
    "            \"$project\": {\n",
    "            \"user_count\": {\"$size\": \"$user_ids\"},\n",
    "            \"activity_count\": {\"$size\": \"$activity_ids\"}\n",
    "            }\n",
    "        }\n",
    "        ]\n",
    "\n",
    "        cursor_t = collection_t.aggregate(pipeline_t)\n",
    "        cursor_a = collection_a.aggregate(pipeline_a)\n",
    "        result_t = list(cursor_t)\n",
    "        result_a = list(cursor_a)\n",
    "        if result_t and result_a:\n",
    "            count_t = result_t[0]['count']\n",
    "            count_u = result_a[0]['user_count']\n",
    "            count_a = result_a[0]['activity_count']\n",
    "            print('Tot TrackPoints: ' + str(count_t) + \n",
    "                  '\\n' + 'Tot Users: ' + str(count_u) +\n",
    "                  '\\n' + 'Tot Activities: ' + str(count_a))\n",
    "        else:\n",
    "            return print('Error')\n",
    "        \n",
    "    ##############################################################################################################\n",
    "\n",
    "    def query2(self):\n",
    "        pipeline2 = [\n",
    "            {\n",
    "                \"$group\": {\n",
    "                \"_id\": \"$user_info.user_id\",\n",
    "                    \"nb\": { \"$sum\": 1} \n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$group\": {\n",
    "                \"_id\": None,\n",
    "                \"avg_nb\": { \"$avg\": \"$nb\" }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "        result2 = list(self.db[\"Activity\"].aggregate(pipeline2))\n",
    "\n",
    "        for doc in result2 :\n",
    "            print(\"Average number of activities per user :\", doc['avg_nb'])\n",
    "\n",
    "    ##############################################################################################################\n",
    "\n",
    "    def query3(self):\n",
    "        pipeline = [\n",
    "            {\n",
    "                \"$group\": {\n",
    "                    \"_id\": \"$user_info.user_id\",\n",
    "                    \"count\": { \"$sum\": 1 }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$sort\": {\"count\": -1}\n",
    "            },\n",
    "            {\n",
    "                \"$limit\": 20\n",
    "            }\n",
    "        ]\n",
    "        result = list(self.db.Activity.aggregate(pipeline))\n",
    "\n",
    "        for doc in result:\n",
    "            pprint(doc)\n",
    "\n",
    "    ##############################################################################################################\n",
    "\n",
    "    def query4(self):\n",
    "        collection_a = self.db['Activity']\n",
    "\n",
    "        pipeline = [\n",
    "            {\n",
    "                '$match': {\n",
    "                    'transportation_mode': 'taxi'\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                '$group': {\n",
    "                    '_id': '$user_info.user_id'\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        cursor_a = collection_a.aggregate(pipeline)\n",
    "        result_a = list(cursor_a)\n",
    "\n",
    "        if result_a:\n",
    "            print('Users that have taken a taki:')\n",
    "            for u in result_a:\n",
    "                pprint(u['_id'])\n",
    "        else:\n",
    "            print(\"Error\")\n",
    "\n",
    "    ##############################################################################################################\n",
    "\n",
    "    def query5(self):\n",
    "        pipeline5 = [\n",
    "            {\n",
    "                \"$match\": {\n",
    "                \"transportation_mode\":{\"$ne\": 'missing'} \n",
    "                \n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$group\": {\n",
    "                \"_id\": \"$transportation_mode\",\n",
    "                    \"nb\": { \"$sum\": 1} \n",
    "                }\n",
    "            }\n",
    "        ]  \n",
    "        result5 = list(self.db[\"Activity\"].aggregate(pipeline5))\n",
    "\n",
    "        for doc in result5 :\n",
    "            print(\"transportation_mode : \",doc[\"_id\"], \", number of activities : \", doc[\"nb\"])\n",
    "\n",
    "    ##############################################################################################################\n",
    "\n",
    "    def query6a(self):\n",
    "        pipeline = [\n",
    "            {\n",
    "                \"$project\": {\n",
    "                    \"year\": { \"$year\": { \"$dateFromString\": { \"dateString\": \"$start_datetime\" } }}\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$group\": {\n",
    "                    \"_id\": \"$year\",\n",
    "                    \"count\": { \"$sum\": 1 }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$sort\": { \"count\": -1 }\n",
    "            },\n",
    "            {\n",
    "                \"$limit\": 1\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        result = list(self.db.Activity.aggregate(pipeline))\n",
    "\n",
    "        for doc in result:\n",
    "            pprint(doc)\n",
    "\n",
    "    ##############################################################################################################\n",
    "\n",
    "    def query6b(self):\n",
    "        pipeline = [\n",
    "            {\n",
    "                \"$addFields\": {\n",
    "                    \"start_datetime\": {\n",
    "                        \"$dateFromString\": {\n",
    "                            \"dateString\": \"$start_datetime\",\n",
    "                            \"format\": \"%Y-%m-%d %H:%M:%S\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"end_datetime\": {\n",
    "                        \"$dateFromString\": {\n",
    "                            \"dateString\": \"$end_datetime\",\n",
    "                            \"format\": \"%Y-%m-%d %H:%M:%S\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$project\": {\n",
    "                    \"year\": { \"$year\": \"$start_datetime\" },\n",
    "                    \"duration\": {\n",
    "                        \"$divide\": [\n",
    "                            { \"$subtract\": [\"$end_datetime\", \"$start_datetime\"] },\n",
    "                            1000 * 60 * 60\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$group\": {\n",
    "                    \"_id\": \"$year\",\n",
    "                    \"total_hours\": { \"$sum\": \"$duration\" }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$sort\": { \"total_hours\": -1 }\n",
    "            },\n",
    "            {\n",
    "                \"$limit\": 1\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        result = list(self.db.Activity.aggregate(pipeline))\n",
    "\n",
    "        for doc in result:\n",
    "            pprint(doc)  \n",
    "\n",
    "    ##############################################################################################################\n",
    "\n",
    "    def query7(self):\n",
    "        \n",
    "        collection_a = self.db['Activity']\n",
    "        collection_t = self.db['TrackPoint']\n",
    "\n",
    "        user_id = '112'\n",
    "        start_date = '2008-01-01 00:00:00'\n",
    "        end_date = '2008-12-31 23:59:59'\n",
    "        mode = 'walk'\n",
    "        \n",
    "        pipeline7a = [\n",
    "                    {\n",
    "                        '$match': {\n",
    "                            'user_info.user_id': user_id,\n",
    "                            'start_datetime': {\n",
    "                                '$gte': start_date,\n",
    "                                '$lte': end_date\n",
    "                            },\n",
    "                            'transportation_mode': mode\n",
    "                        }\n",
    "                    },\n",
    "                {\n",
    "                    \"$project\": {\n",
    "                        \"activity_id\": \"$activity_id\",\n",
    "                        \n",
    "                }\n",
    "                }]\n",
    "    \n",
    "        cursor_a = collection_a.aggregate(pipeline7a)\n",
    "        result7a = list(cursor_a)\n",
    "\n",
    "        list_act=[]\n",
    "        for doc in result7a :\n",
    "            list_act.append(doc[\"activity_id\"])\n",
    "      \n",
    "        pipeline7b = [\n",
    "        \n",
    "            {\n",
    "                \"$match\" : {\n",
    "                    \"activity_id\" : {\"$in\" : list_act}\n",
    "                    }\n",
    "            },\n",
    "            {\n",
    "                \"$sort\": { \"trackpoint_id\": 1 }\n",
    "            },\n",
    "            {\n",
    "                \"$group\": {\n",
    "                \"_id\": \"$activity_id\",\n",
    "                \"list_lat\": {\"$push\": \"$lat\"},\n",
    "                \"list_lon\": {\"$push\": \"$lon\"},\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$project\": {\n",
    "                    \"activity_id\": \"$_id\",\n",
    "                    \"list_lat\":\"$list_lat\",\n",
    "                    \"list_lon\":\"$list_lon\"\n",
    "                    \n",
    "                }\n",
    "            }\n",
    "\n",
    "            ]\n",
    "      \n",
    "        cursor_t = collection_t.aggregate(pipeline7b)\n",
    "        result7b = list(cursor_t)\n",
    "\n",
    "        tot = 0\n",
    "        for act in result7b :\n",
    "            tot_act = 0 \n",
    "            prev_lat = 0\n",
    "            prev_lon = 0\n",
    "            \n",
    "            for lat,lon in zip(act[\"list_lat\"],act[\"list_lon\"]):\n",
    "\n",
    "                if prev_lat != lat and prev_lon != lon :\n",
    "                    d = haversine_distance([prev_lon,prev_lat], [lon, lat])\n",
    "                    tot_act = tot_act + d\n",
    "\n",
    "            tot = tot + tot_act\n",
    "        print('Total distance is', str(tot))\n",
    "\n",
    "    ##############################################################################################################\n",
    "\n",
    "    def query8(self):\n",
    "        pipeline8 = [\n",
    "                \n",
    "                {\n",
    "                    \"$sort\": { \"trackpoint_id\": 1 }\n",
    "                },\n",
    "                {\n",
    "                    \"$group\": {\n",
    "                    \"_id\": \"$activity_id\",\n",
    "                    \"list_alt\": {\"$push\": \"$altitude\"},\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"$lookup\": {\n",
    "                    \"from\": \"Activity\",\n",
    "                    \"localField\": \"_id\",\n",
    "                    \"foreignField\": \"activity_id\",\n",
    "                    \"as\": \"activity\"\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"$project\": {\n",
    "                        \"user_id\" : \"$activity.user_info.user_id\",\n",
    "                        \"activity_id\": \"$_id\",\n",
    "                        \"list_alt\": \"$list_alt\" \n",
    "                }\n",
    "                }\n",
    "                ]\n",
    "        result8 = list(self.db[\"TrackPoint\"].aggregate(pipeline8))\n",
    "\n",
    "        alt_user = {}\n",
    "        for activite in result8: \n",
    "            prev_alt = 0\n",
    "            alt_act = 0\n",
    "            user= activite[\"user_id\"][0]\n",
    "            for alt in activite[\"list_alt\"] :\n",
    "                if prev_alt != 0 and prev_alt < alt :\n",
    "                    alt_act = alt_act + (alt-prev_alt)\n",
    "                prev_alt = alt\n",
    "            if user in alt_user.keys() :\n",
    "                alt_user[user]= alt_user[user] + alt_act\n",
    "            else : \n",
    "                alt_user[user]= alt_act\n",
    "\n",
    "        dico_sorted = {k: v for k, v in sorted(alt_user.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "        for i, (key, value) in enumerate(dico_sorted.items()):\n",
    "            if i < 20:\n",
    "                print(f\"user_id : {key}, altitude_gained : {value}\")\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    ##############################################################################################################\n",
    "\n",
    "    def query9(self):   \n",
    "        pipeline = [\n",
    "                    {\n",
    "                    \"$sort\": { \"trackpoint_id\": 1 }\n",
    "                },\n",
    "                {\n",
    "                    \"$group\": {\n",
    "                    \"_id\": \"$activity_id\",\n",
    "                    \"list_dates\": {\"$push\": \"$date_time\"},\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"$lookup\": {\n",
    "                    \"from\": \"Activity\",\n",
    "                    \"localField\": \"_id\",\n",
    "                    \"foreignField\": \"activity_id\",\n",
    "                    \"as\": \"activity\"\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"$project\": {\n",
    "                        \"user_id\" : \"$activity.user_info.user_id\",\n",
    "                        \"activity_id\": \"$_id\",\n",
    "                        \"list_dates\": \"$list_dates\"\n",
    "                }\n",
    "                }\n",
    "                ]\n",
    "        result = list(self.db.TrackPoint.aggregate(pipeline))\n",
    "\n",
    "        def is_invalid_timestamp(timestamp1, timestamp2):\n",
    "            time_format = '%Y-%m-%d %H:%M:%S'\n",
    "            dt1 = datetime.strptime(timestamp1, time_format)\n",
    "            dt2 = datetime.strptime(timestamp2, time_format)\n",
    "            return abs((dt2 - dt1).total_seconds()) >= 300 \n",
    "\n",
    "        invalid_activities = {}\n",
    "\n",
    "        for item in result:\n",
    "            user_id = item['user_id'][0]\n",
    "            trackpoints = item['list_dates']\n",
    "            invalid_count = 0\n",
    "            \n",
    "            for i in range(1, len(trackpoints)):\n",
    "                if is_invalid_timestamp(trackpoints[i - 1], trackpoints[i]):\n",
    "                    invalid_count += 1\n",
    "            \n",
    "            if invalid_count > 0:\n",
    "                if user_id in invalid_activities:\n",
    "                    invalid_activities[user_id] += invalid_count\n",
    "                else:\n",
    "                    invalid_activities[user_id] = invalid_count\n",
    "\n",
    "        for user_id, count in invalid_activities.items():\n",
    "            print(f\"user_id: {user_id}, invalid_activities: {count}\")    \n",
    "\n",
    "    ##############################################################################################################\n",
    "\n",
    "    def query10(self):\n",
    "        collection_t = self.db['TrackPoint']\n",
    "\n",
    "        # Define the central coordinate\n",
    "        center_lat = 39.916\n",
    "        center_lon = 116.397\n",
    "\n",
    "        # Max distance in km\n",
    "        max_distance_km = 5\n",
    "        max_dist_degrees = (max_distance_km / 40075) * 360\n",
    "        # Earth's circumference = 40 075\n",
    "        # 360Â°\n",
    "\n",
    "\n",
    "        pipeline = [\n",
    "            {\n",
    "                \"$match\": {\n",
    "                    \"lon\": {\n",
    "                        \"$gte\": center_lon - max_dist_degrees,\n",
    "                        \"$lte\": center_lon + max_dist_degrees\n",
    "                    },\n",
    "                    \"lat\": {\n",
    "                        \"$gte\": center_lat - max_dist_degrees,\n",
    "                        \"$lte\": center_lat + max_dist_degrees\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$lookup\": {\n",
    "                    \"from\": \"Activity\", \n",
    "                    \"localField\": \"activity_id\",  \n",
    "                    \"foreignField\": \"activity_id\", \n",
    "                    \"as\": \"activity_info\"  \n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$unwind\": \"$activity_info\"\n",
    "            },\n",
    "            {\n",
    "                '$group': {\n",
    "                    '_id': '$activity_info.user_info.user_id'\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        cursor_t = collection_t.aggregate(pipeline)\n",
    "        result_t = list(cursor_t)\n",
    "\n",
    "        if result_t:\n",
    "            print('Users who have tracked an activity in the Forbidden City of Beijing')\n",
    "            for r in result_t:\n",
    "                print(r)\n",
    "        else:\n",
    "            print(\"Error\")\n",
    "\n",
    "    ##############################################################################################################\n",
    "\n",
    "    def query11(self):\n",
    "        pipeline11 = [\n",
    "                {\n",
    "                    \"$match\": {\n",
    "                    \"transportation_mode\":{\"$ne\": \"missing\"} \n",
    "                    \n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"$group\": {\n",
    "                    \"_id\": {\"transportation_mode\":\"$transportation_mode\",\n",
    "                            \"user_id\":\"$user_info.user_id\"},\n",
    "                        \"nb\": { \"$sum\": 1} \n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    '$sort': {\n",
    "                        '_id.user_id': 1,\n",
    "                        'nb': -1\n",
    "                        }\n",
    "                },\n",
    "                {\n",
    "                    \"$group\": {\n",
    "                    \"_id\": \"$_id.user_id\",\n",
    "                        \"most_used_mode\": { '$first': '$_id.transportation_mode'} \n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    '$sort': {\n",
    "                        '_id': 1,\n",
    "                    \n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    '$project': {\n",
    "                        '_id': 0,\n",
    "                        'user_id': '$_id',\n",
    "                        'most_used_transportation_mode': '$most_used_mode'\n",
    "                    }\n",
    "                }\n",
    "                ]\n",
    "        result11 = list(self.db[\"Activity\"].aggregate(pipeline11))\n",
    "\n",
    "        for doc in result11 :\n",
    "            print(\"user_id : \",doc[\"user_id\"], \", most_used_transportation_mode : \", doc[\"most_used_transportation_mode\"])\n",
    "             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are connected to the database: my_db\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "Output query 1 :\n",
      "\n",
      "Tot TrackPoints: 9682005\n",
      "Tot Users: 173\n",
      "Tot Activities: 16048\n",
      "\n",
      "Output query 2 :\n",
      "\n",
      "Average number of activities per user : 92.76878612716763\n",
      "\n",
      "Output query 3 :\n",
      "\n",
      "{'_id': '128', 'count': 2102}\n",
      "{'_id': '153', 'count': 1793}\n",
      "{'_id': '025', 'count': 715}\n",
      "{'_id': '163', 'count': 704}\n",
      "{'_id': '062', 'count': 691}\n",
      "{'_id': '144', 'count': 563}\n",
      "{'_id': '041', 'count': 399}\n",
      "{'_id': '085', 'count': 364}\n",
      "{'_id': '004', 'count': 346}\n",
      "{'_id': '140', 'count': 345}\n",
      "{'_id': '167', 'count': 320}\n",
      "{'_id': '068', 'count': 280}\n",
      "{'_id': '017', 'count': 265}\n",
      "{'_id': '003', 'count': 261}\n",
      "{'_id': '014', 'count': 236}\n",
      "{'_id': '126', 'count': 215}\n",
      "{'_id': '030', 'count': 210}\n",
      "{'_id': '112', 'count': 208}\n",
      "{'_id': '011', 'count': 201}\n",
      "{'_id': '039', 'count': 198}\n",
      "\n",
      "Output query 4 :\n",
      "\n",
      "Users that have taken a taki:\n",
      "'163'\n",
      "'058'\n",
      "'062'\n",
      "'085'\n",
      "'078'\n",
      "'098'\n",
      "'010'\n",
      "'128'\n",
      "'111'\n",
      "'080'\n",
      "\n",
      "Output query 5 :\n",
      "\n",
      "transportation_mode :  boat , number of activities :  1\n",
      "transportation_mode :  bus , number of activities :  199\n",
      "transportation_mode :  taxi , number of activities :  37\n",
      "transportation_mode :  airplane , number of activities :  3\n",
      "transportation_mode :  train , number of activities :  2\n",
      "transportation_mode :  run , number of activities :  1\n",
      "transportation_mode :  walk , number of activities :  481\n",
      "transportation_mode :  bike , number of activities :  263\n",
      "transportation_mode :  car , number of activities :  419\n",
      "transportation_mode :  subway , number of activities :  133\n",
      "\n",
      "Output query 6a :\n",
      "\n",
      "{'_id': 2008, 'count': 5895}\n",
      "\n",
      "Output query 6b :\n",
      "\n",
      "{'_id': 2009, 'total_hours': 11612.423888888889}\n",
      "\n",
      "Output query 7 :\n",
      "\n",
      "Total distance is 289503338.837764\n",
      "\n",
      "Output query 8 :\n",
      "\n",
      "user_id : 128, altitude_gained : 2131329\n",
      "user_id : 153, altitude_gained : 1818335\n",
      "user_id : 004, altitude_gained : 1088479\n",
      "user_id : 041, altitude_gained : 788948\n",
      "user_id : 003, altitude_gained : 765411\n",
      "user_id : 085, altitude_gained : 713570\n",
      "user_id : 163, altitude_gained : 671777\n",
      "user_id : 062, altitude_gained : 595103\n",
      "user_id : 144, altitude_gained : 586133\n",
      "user_id : 030, altitude_gained : 575652\n",
      "user_id : 039, altitude_gained : 481028\n",
      "user_id : 084, altitude_gained : 429847\n",
      "user_id : 000, altitude_gained : 398211\n",
      "user_id : 002, altitude_gained : 377283\n",
      "user_id : 167, altitude_gained : 369845\n",
      "user_id : 025, altitude_gained : 357165\n",
      "user_id : 037, altitude_gained : 325403\n",
      "user_id : 140, altitude_gained : 310929\n",
      "user_id : 126, altitude_gained : 271840\n",
      "user_id : 017, altitude_gained : 205170\n",
      "\n",
      "Output query 9 :\n",
      "\n",
      "user_id: 135, invalid_activities: 21\n",
      "user_id: 132, invalid_activities: 3\n",
      "user_id: 104, invalid_activities: 351\n",
      "user_id: 103, invalid_activities: 44\n",
      "user_id: 168, invalid_activities: 36\n",
      "user_id: 157, invalid_activities: 65\n",
      "user_id: 150, invalid_activities: 60\n",
      "user_id: 159, invalid_activities: 7\n",
      "user_id: 166, invalid_activities: 4\n",
      "user_id: 161, invalid_activities: 7\n",
      "user_id: 102, invalid_activities: 16\n",
      "user_id: 105, invalid_activities: 35\n",
      "user_id: 133, invalid_activities: 18\n",
      "user_id: 134, invalid_activities: 83\n",
      "user_id: 158, invalid_activities: 28\n",
      "user_id: 167, invalid_activities: 334\n",
      "user_id: 151, invalid_activities: 4\n",
      "user_id: 169, invalid_activities: 12\n",
      "user_id: 024, invalid_activities: 75\n",
      "user_id: 023, invalid_activities: 30\n",
      "user_id: 015, invalid_activities: 138\n",
      "user_id: 012, invalid_activities: 163\n",
      "user_id: 079, invalid_activities: 3\n",
      "user_id: 046, invalid_activities: 26\n",
      "user_id: 041, invalid_activities: 389\n",
      "user_id: 048, invalid_activities: 5\n",
      "user_id: 077, invalid_activities: 11\n",
      "user_id: 083, invalid_activities: 56\n",
      "user_id: 084, invalid_activities: 230\n",
      "user_id: 070, invalid_activities: 16\n",
      "user_id: 013, invalid_activities: 69\n",
      "user_id: 014, invalid_activities: 328\n",
      "user_id: 022, invalid_activities: 191\n",
      "user_id: 025, invalid_activities: 426\n",
      "user_id: 071, invalid_activities: 64\n",
      "user_id: 085, invalid_activities: 384\n",
      "user_id: 082, invalid_activities: 65\n",
      "user_id: 076, invalid_activities: 33\n",
      "user_id: 040, invalid_activities: 52\n",
      "user_id: 078, invalid_activities: 26\n",
      "user_id: 047, invalid_activities: 19\n",
      "user_id: 065, invalid_activities: 46\n",
      "user_id: 091, invalid_activities: 110\n",
      "user_id: 096, invalid_activities: 67\n",
      "user_id: 062, invalid_activities: 397\n",
      "user_id: 054, invalid_activities: 8\n",
      "user_id: 053, invalid_activities: 39\n",
      "user_id: 098, invalid_activities: 25\n",
      "user_id: 038, invalid_activities: 266\n",
      "user_id: 007, invalid_activities: 136\n",
      "user_id: 000, invalid_activities: 445\n",
      "user_id: 009, invalid_activities: 114\n",
      "user_id: 036, invalid_activities: 126\n",
      "user_id: 031, invalid_activities: 7\n",
      "user_id: 052, invalid_activities: 138\n",
      "user_id: 099, invalid_activities: 113\n",
      "user_id: 055, invalid_activities: 28\n",
      "user_id: 063, invalid_activities: 27\n",
      "user_id: 097, invalid_activities: 27\n",
      "user_id: 090, invalid_activities: 15\n",
      "user_id: 064, invalid_activities: 10\n",
      "user_id: 030, invalid_activities: 511\n",
      "user_id: 008, invalid_activities: 33\n",
      "user_id: 037, invalid_activities: 279\n",
      "user_id: 001, invalid_activities: 116\n",
      "user_id: 039, invalid_activities: 427\n",
      "user_id: 006, invalid_activities: 49\n",
      "user_id: 174, invalid_activities: 188\n",
      "user_id: 180, invalid_activities: 2\n",
      "user_id: 173, invalid_activities: 11\n",
      "user_id: 145, invalid_activities: 17\n",
      "user_id: 142, invalid_activities: 200\n",
      "user_id: 129, invalid_activities: 41\n",
      "user_id: 111, invalid_activities: 251\n",
      "user_id: 118, invalid_activities: 31\n",
      "user_id: 127, invalid_activities: 8\n",
      "user_id: 144, invalid_activities: 551\n",
      "user_id: 172, invalid_activities: 21\n",
      "user_id: 181, invalid_activities: 49\n",
      "user_id: 175, invalid_activities: 20\n",
      "user_id: 121, invalid_activities: 15\n",
      "user_id: 119, invalid_activities: 79\n",
      "user_id: 126, invalid_activities: 242\n",
      "user_id: 110, invalid_activities: 48\n",
      "user_id: 128, invalid_activities: 1288\n",
      "user_id: 117, invalid_activities: 3\n",
      "user_id: 153, invalid_activities: 1154\n",
      "user_id: 154, invalid_activities: 28\n",
      "user_id: 162, invalid_activities: 27\n",
      "user_id: 165, invalid_activities: 4\n",
      "user_id: 131, invalid_activities: 59\n",
      "user_id: 136, invalid_activities: 34\n",
      "user_id: 109, invalid_activities: 9\n",
      "user_id: 100, invalid_activities: 5\n",
      "user_id: 107, invalid_activities: 2\n",
      "user_id: 138, invalid_activities: 27\n",
      "user_id: 164, invalid_activities: 20\n",
      "user_id: 163, invalid_activities: 559\n",
      "user_id: 155, invalid_activities: 70\n",
      "user_id: 152, invalid_activities: 4\n",
      "user_id: 106, invalid_activities: 66\n",
      "user_id: 139, invalid_activities: 50\n",
      "user_id: 101, invalid_activities: 166\n",
      "user_id: 108, invalid_activities: 28\n",
      "user_id: 130, invalid_activities: 18\n",
      "user_id: 089, invalid_activities: 116\n",
      "user_id: 042, invalid_activities: 118\n",
      "user_id: 045, invalid_activities: 19\n",
      "user_id: 087, invalid_activities: 3\n",
      "user_id: 073, invalid_activities: 30\n",
      "user_id: 074, invalid_activities: 19\n",
      "user_id: 080, invalid_activities: 8\n",
      "user_id: 020, invalid_activities: 27\n",
      "user_id: 027, invalid_activities: 14\n",
      "user_id: 018, invalid_activities: 97\n",
      "user_id: 011, invalid_activities: 38\n",
      "user_id: 016, invalid_activities: 61\n",
      "user_id: 029, invalid_activities: 37\n",
      "user_id: 081, invalid_activities: 42\n",
      "user_id: 075, invalid_activities: 8\n",
      "user_id: 072, invalid_activities: 6\n",
      "user_id: 086, invalid_activities: 19\n",
      "user_id: 044, invalid_activities: 83\n",
      "user_id: 088, invalid_activities: 13\n",
      "user_id: 043, invalid_activities: 73\n",
      "user_id: 017, invalid_activities: 493\n",
      "user_id: 028, invalid_activities: 91\n",
      "user_id: 010, invalid_activities: 154\n",
      "user_id: 026, invalid_activities: 51\n",
      "user_id: 019, invalid_activities: 65\n",
      "user_id: 021, invalid_activities: 72\n",
      "user_id: 003, invalid_activities: 849\n",
      "user_id: 004, invalid_activities: 1173\n",
      "user_id: 032, invalid_activities: 37\n",
      "user_id: 035, invalid_activities: 124\n",
      "user_id: 095, invalid_activities: 20\n",
      "user_id: 061, invalid_activities: 41\n",
      "user_id: 066, invalid_activities: 40\n",
      "user_id: 092, invalid_activities: 315\n",
      "user_id: 059, invalid_activities: 8\n",
      "user_id: 050, invalid_activities: 17\n",
      "user_id: 057, invalid_activities: 60\n",
      "user_id: 068, invalid_activities: 327\n",
      "user_id: 034, invalid_activities: 241\n",
      "user_id: 033, invalid_activities: 3\n",
      "user_id: 005, invalid_activities: 127\n",
      "user_id: 002, invalid_activities: 296\n",
      "user_id: 056, invalid_activities: 11\n",
      "user_id: 069, invalid_activities: 65\n",
      "user_id: 051, invalid_activities: 146\n",
      "user_id: 093, invalid_activities: 4\n",
      "user_id: 067, invalid_activities: 83\n",
      "user_id: 058, invalid_activities: 25\n",
      "user_id: 060, invalid_activities: 1\n",
      "user_id: 094, invalid_activities: 60\n",
      "user_id: 112, invalid_activities: 140\n",
      "user_id: 115, invalid_activities: 183\n",
      "user_id: 123, invalid_activities: 21\n",
      "user_id: 124, invalid_activities: 12\n",
      "user_id: 170, invalid_activities: 2\n",
      "user_id: 141, invalid_activities: 1\n",
      "user_id: 146, invalid_activities: 28\n",
      "user_id: 179, invalid_activities: 42\n",
      "user_id: 125, invalid_activities: 69\n",
      "user_id: 122, invalid_activities: 21\n",
      "user_id: 114, invalid_activities: 4\n",
      "user_id: 113, invalid_activities: 1\n",
      "user_id: 147, invalid_activities: 64\n",
      "user_id: 140, invalid_activities: 195\n",
      "user_id: 176, invalid_activities: 24\n",
      "user_id: 171, invalid_activities: 14\n",
      "\n",
      "Output query 10 :\n",
      "\n",
      "Users who have tracked an activity in the Forbidden City of Beijing\n",
      "{'_id': '090'}\n",
      "{'_id': '050'}\n",
      "{'_id': '085'}\n",
      "{'_id': '114'}\n",
      "{'_id': '174'}\n",
      "{'_id': '163'}\n",
      "{'_id': '140'}\n",
      "{'_id': '002'}\n",
      "{'_id': '010'}\n",
      "{'_id': '013'}\n",
      "{'_id': '081'}\n",
      "{'_id': '086'}\n",
      "{'_id': '103'}\n",
      "{'_id': '057'}\n",
      "{'_id': '125'}\n",
      "{'_id': '084'}\n",
      "{'_id': '042'}\n",
      "{'_id': '078'}\n",
      "{'_id': '015'}\n",
      "{'_id': '091'}\n",
      "{'_id': '117'}\n",
      "{'_id': '073'}\n",
      "{'_id': '139'}\n",
      "{'_id': '168'}\n",
      "{'_id': '121'}\n",
      "{'_id': '126'}\n",
      "{'_id': '008'}\n",
      "{'_id': '000'}\n",
      "{'_id': '083'}\n",
      "{'_id': '108'}\n",
      "{'_id': '019'}\n",
      "{'_id': '157'}\n",
      "{'_id': '093'}\n",
      "{'_id': '071'}\n",
      "{'_id': '101'}\n",
      "{'_id': '144'}\n",
      "{'_id': '159'}\n",
      "{'_id': '040'}\n",
      "{'_id': '136'}\n",
      "{'_id': '038'}\n",
      "{'_id': '044'}\n",
      "{'_id': '001'}\n",
      "{'_id': '059'}\n",
      "{'_id': '096'}\n",
      "{'_id': '102'}\n",
      "{'_id': '123'}\n",
      "{'_id': '051'}\n",
      "{'_id': '034'}\n",
      "{'_id': '028'}\n",
      "{'_id': '112'}\n",
      "{'_id': '004'}\n",
      "{'_id': '037'}\n",
      "{'_id': '025'}\n",
      "{'_id': '119'}\n",
      "{'_id': '097'}\n",
      "{'_id': '138'}\n",
      "{'_id': '058'}\n",
      "{'_id': '020'}\n",
      "{'_id': '047'}\n",
      "{'_id': '161'}\n",
      "{'_id': '018'}\n",
      "{'_id': '094'}\n",
      "{'_id': '099'}\n",
      "{'_id': '110'}\n",
      "{'_id': '134'}\n",
      "{'_id': '030'}\n",
      "{'_id': '154'}\n",
      "{'_id': '082'}\n",
      "{'_id': '145'}\n",
      "{'_id': '074'}\n",
      "{'_id': '026'}\n",
      "{'_id': '056'}\n",
      "{'_id': '147'}\n",
      "{'_id': '055'}\n",
      "{'_id': '062'}\n",
      "{'_id': '061'}\n",
      "{'_id': '155'}\n",
      "{'_id': '088'}\n",
      "{'_id': '005'}\n",
      "{'_id': '106'}\n",
      "{'_id': '012'}\n",
      "{'_id': '067'}\n",
      "{'_id': '107'}\n",
      "{'_id': '022'}\n",
      "{'_id': '068'}\n",
      "{'_id': '011'}\n",
      "{'_id': '065'}\n",
      "{'_id': '043'}\n",
      "{'_id': '113'}\n",
      "{'_id': '142'}\n",
      "{'_id': '009'}\n",
      "{'_id': '153'}\n",
      "{'_id': '039'}\n",
      "{'_id': '052'}\n",
      "{'_id': '029'}\n",
      "{'_id': '089'}\n",
      "{'_id': '092'}\n",
      "{'_id': '115'}\n",
      "{'_id': '128'}\n",
      "{'_id': '167'}\n",
      "{'_id': '017'}\n",
      "{'_id': '016'}\n",
      "{'_id': '014'}\n",
      "{'_id': '104'}\n",
      "{'_id': '171'}\n",
      "{'_id': '045'}\n",
      "{'_id': '105'}\n",
      "{'_id': '076'}\n",
      "{'_id': '169'}\n",
      "{'_id': '176'}\n",
      "{'_id': '158'}\n",
      "{'_id': '035'}\n",
      "{'_id': '041'}\n",
      "{'_id': '003'}\n",
      "{'_id': '111'}\n",
      "{'_id': '095'}\n",
      "{'_id': '150'}\n",
      "{'_id': '124'}\n",
      "{'_id': '046'}\n",
      "{'_id': '141'}\n",
      "\n",
      "Output query 11 :\n",
      "\n",
      "user_id :  010 , most_used_transportation_mode :  taxi\n",
      "user_id :  020 , most_used_transportation_mode :  bike\n",
      "user_id :  021 , most_used_transportation_mode :  walk\n",
      "user_id :  052 , most_used_transportation_mode :  bus\n",
      "user_id :  056 , most_used_transportation_mode :  bike\n",
      "user_id :  058 , most_used_transportation_mode :  taxi\n",
      "user_id :  060 , most_used_transportation_mode :  walk\n",
      "user_id :  062 , most_used_transportation_mode :  walk\n",
      "user_id :  064 , most_used_transportation_mode :  bike\n",
      "user_id :  065 , most_used_transportation_mode :  bike\n",
      "user_id :  067 , most_used_transportation_mode :  walk\n",
      "user_id :  069 , most_used_transportation_mode :  bike\n",
      "user_id :  073 , most_used_transportation_mode :  walk\n",
      "user_id :  075 , most_used_transportation_mode :  walk\n",
      "user_id :  076 , most_used_transportation_mode :  car\n",
      "user_id :  078 , most_used_transportation_mode :  walk\n",
      "user_id :  080 , most_used_transportation_mode :  bike\n",
      "user_id :  081 , most_used_transportation_mode :  bike\n",
      "user_id :  082 , most_used_transportation_mode :  walk\n",
      "user_id :  084 , most_used_transportation_mode :  walk\n",
      "user_id :  085 , most_used_transportation_mode :  walk\n",
      "user_id :  086 , most_used_transportation_mode :  car\n",
      "user_id :  087 , most_used_transportation_mode :  walk\n",
      "user_id :  089 , most_used_transportation_mode :  car\n",
      "user_id :  091 , most_used_transportation_mode :  walk\n",
      "user_id :  092 , most_used_transportation_mode :  bus\n",
      "user_id :  097 , most_used_transportation_mode :  bike\n",
      "user_id :  098 , most_used_transportation_mode :  taxi\n",
      "user_id :  101 , most_used_transportation_mode :  car\n",
      "user_id :  102 , most_used_transportation_mode :  bike\n",
      "user_id :  107 , most_used_transportation_mode :  walk\n",
      "user_id :  108 , most_used_transportation_mode :  walk\n",
      "user_id :  111 , most_used_transportation_mode :  taxi\n",
      "user_id :  112 , most_used_transportation_mode :  walk\n",
      "user_id :  115 , most_used_transportation_mode :  car\n",
      "user_id :  117 , most_used_transportation_mode :  walk\n",
      "user_id :  125 , most_used_transportation_mode :  bike\n",
      "user_id :  126 , most_used_transportation_mode :  bike\n",
      "user_id :  128 , most_used_transportation_mode :  car\n",
      "user_id :  136 , most_used_transportation_mode :  walk\n",
      "user_id :  138 , most_used_transportation_mode :  bike\n",
      "user_id :  139 , most_used_transportation_mode :  bike\n",
      "user_id :  144 , most_used_transportation_mode :  walk\n",
      "user_id :  153 , most_used_transportation_mode :  walk\n",
      "user_id :  161 , most_used_transportation_mode :  walk\n",
      "user_id :  163 , most_used_transportation_mode :  bike\n",
      "user_id :  167 , most_used_transportation_mode :  bike\n",
      "user_id :  175 , most_used_transportation_mode :  bus\n",
      "\n",
      "-----------------------------------------------\n",
      "Connection to my_db-db is closed\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    program = None\n",
    "    try:\n",
    "        program = Task2()\n",
    "\n",
    "        print(\"\\nOutput query 1 :\\n\")\n",
    "        program.query1()\n",
    "        print(\"\\nOutput query 2 :\\n\")\n",
    "        program.query2()\n",
    "        print(\"\\nOutput query 3 :\\n\")\n",
    "        program.query3()\n",
    "        print(\"\\nOutput query 4 :\\n\")\n",
    "        program.query4()\n",
    "        print(\"\\nOutput query 5 :\\n\")\n",
    "        program.query5()\n",
    "        print(\"\\nOutput query 6a :\\n\")\n",
    "        program.query6a()\n",
    "        print(\"\\nOutput query 6b :\\n\")\n",
    "        program.query6b()\n",
    "        print(\"\\nOutput query 7 :\\n\")\n",
    "        program.query7()\n",
    "        print(\"\\nOutput query 8 :\\n\")\n",
    "        program.query8()\n",
    "        print(\"\\nOutput query 9 :\\n\")\n",
    "        program.query9()\n",
    "        print(\"\\nOutput query 10 :\\n\")\n",
    "        program.query10()\n",
    "        print(\"\\nOutput query 11 :\\n\")\n",
    "        program.query11()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"ERROR: Failed to use database:\", e)\n",
    "    finally:\n",
    "        if program:\n",
    "            program.connection.close_connection()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
